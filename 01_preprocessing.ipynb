{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "_ = nltk.download(\"stopwords\", quiet=True)\n",
    "_ = nltk.download(\"punkt\", quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data/02_postprocessing direction if it does not exist\n",
    "if not os.path.exists(\"data/02_postprocessing\"):\n",
    "    os.makedirs(\"data/02_postprocessing\")\n",
    "# Create the data/02_postprocessing/sample directory if it does not exist\n",
    "if not os.path.exists(\"data/02_postprocessing/sample\"):\n",
    "    os.makedirs(\"data/02_postprocessing/sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silent_remove(filename):\n",
    "    try:\n",
    "        os.remove(filename)\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed so that it can be run on the sample data or the full data just by switching one variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to True to run the script on the sample data\n",
    "# Set this to False to run the script on the full data (takes much longer)\n",
    "SAMPLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section performs rating normalization (technically standardization) to all ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ratings and users data\n",
    "file_name = f\"data/01_cleaned/{'sample/' if SAMPLE else ''}ratings.csv\"\n",
    "ratings = pd.read_csv(file_name, header=0)\n",
    "file_name = f\"data/01_cleaned/{'sample/' if SAMPLE else ''}users.csv\"\n",
    "users = pd.read_csv(file_name, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index on the \"user_id\" and \"rating_id\" columns\n",
    "ratings = ratings.set_index([\"user_id\", \"rating_id\"])\n",
    "# Index on the \"user_id\" column for the users data\n",
    "users = users.set_index(\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of ratings for each user_id in the ratings data frame\n",
    "user_ratings = ratings.groupby(\"user_id\").agg(\n",
    "    num_ratings = pd.NamedAgg(column=\"stars\", aggfunc=\"count\"),\n",
    "    mean_rating = pd.NamedAgg(column=\"stars\", aggfunc=\"mean\"),\n",
    "    std_rating = pd.NamedAgg(column=\"stars\", aggfunc=\"std\"),\n",
    ")\n",
    "user_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a \"num_ratings\" to the users data frame by joining the users and user_ratings data frames\n",
    "users = users.join(user_ratings, on=\"user_id\", how=\"left\")\n",
    "# Set null values to 0\n",
    "users[\"num_ratings\"].fillna(0, inplace=True)\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a \"above_cutoff\" column to the users data frame\n",
    "# This column is True if the user has more than \"cutoff\" ratings in the ratings data frame\n",
    "cutoff = 5 # TODO justify this\n",
    "users[\"above_cutoff\"] = users[\"num_ratings\"] > cutoff\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings[\"std_rating\"] = np.NaN\n",
    "cutoff_users = users[users[\"above_cutoff\"]]\n",
    "ratings.loc[cutoff_users.index, \"std_rating\"] = (\n",
    "    ratings.loc[cutoff_users.index, \"stars\"] - cutoff_users[\"mean_rating\"]\n",
    ") / cutoff_users[\"std_rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.loc[cutoff_users.index].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_users = users[~users[\"above_cutoff\"]]\n",
    "other_mean = ratings.loc[other_users.index, \"stars\"].mean()\n",
    "other_std = ratings.loc[other_users.index, \"stars\"].std()\n",
    "ratings.loc[other_users.index, \"std_rating\"] = (\n",
    "    ratings.loc[other_users.index, \"stars\"] - other_mean\n",
    ") / other_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.loc[other_users.index].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_std = ratings[\"std_rating\"].min()\n",
    "max_std = ratings[\"std_rating\"].max()\n",
    "ratings[\"norm_std_rating\"] = (((ratings[\"std_rating\"] - min_std) / (max_std - min_std)) * 4) + 1\n",
    "ratings.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reindexed_ratings = ratings.reset_index()\n",
    "reindexed_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f\"data/02_postprocessing/{'sample/' if SAMPLE else ''}ratings.csv\"\n",
    "with open(file_name, \"w\") as f:\n",
    "    reindexed_ratings.to_csv(f, index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Businesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories >> Type, Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}businesses.json\") as f:\n",
    "    businesses = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count most frequently category occurrences in businesses.json\n",
    "category_counts = {}\n",
    "for business in businesses:\n",
    "    categories_str = business.get(\"categories\", '')\n",
    "    if categories_str:\n",
    "        categories = categories_str.split(', ')\n",
    "        for category in categories:\n",
    "            category_counts[category] = category_counts.get(category, 0) + 1\n",
    "\n",
    "# Find the most frequent categories\n",
    "category_counts = sorted(category_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "category_counts[:1000]\n",
    "\n",
    "# Create a list of the most frequent categories\n",
    "top_categories = [category[0] for category in category_counts[:1000]]\n",
    "\n",
    "# print the top 500 most frequent categories\n",
    "print(top_categories)\n",
    "\n",
    "# Keep only the businesses that have at least one of the top 5 categories using a dictionary and create a new attribute \"type\" for each business that states which of the top 5 categories it belongs to\n",
    "businesses_dict = {}\n",
    "for business in businesses:\n",
    "    categories_str = business.get(\"categories\", '')\n",
    "    if categories_str:\n",
    "        categories = categories_str.split(', ')\n",
    "        for category in categories:\n",
    "            if category in top_categories:\n",
    "                business[\"type\"] = category\n",
    "                businesses_dict[business[\"business_id\"]] = business\n",
    "                break\n",
    "        else:\n",
    "            # If no matching category is found, assign the business to the \"Other\" category\n",
    "            business[\"type\"] = \"Other\"\n",
    "            businesses_dict[business[\"business_id\"]] = business\n",
    "\n",
    "# Define category grouping based on similarity\n",
    "category_groups = {\n",
    "    'Restaurants': ['Restaurants','Food', 'Breakfast & Brunch', 'Fast Food', 'Burgers', 'Pizza', 'Sandwiches', 'American (Traditional)', 'American (New)', 'Mexican', 'Chicken Wings', 'Salad', 'Chinese', 'Cafes', 'Sushi Bars', 'Barbeque', 'Southern', 'Japanese', 'Steakhouses', 'Juice Bars & Smoothies', 'Asian Fusion', 'Diners', 'Tex-Mex', 'Thai', 'Mediterranean', 'Indian', 'Vietnamese', 'Cajun/Creole', 'Latin American', 'Cuban', 'Puerto Rican', 'Caribbean', 'Japanese', 'Spanish', 'Korean', 'French', 'Halal', 'Mongolian', 'Canadian (New)', 'Filipino', 'Greek', 'Brazilian', 'Argentine', 'Hawaiian', 'Afghan', 'Indonesian', 'German', 'Ramen', 'Poke', 'Hot Pot', 'German', 'Pakistani', 'Uzbek', 'Persian/Iranian', 'Russian', 'Burmese', 'New Mexican Cuisine'],\n",
    "    'Shopping': ['Shopping', 'Fashion', 'Specialty Food', 'Bakeries', 'Grocery', 'Flowers & Gifts', 'Furniture Stores', 'Jewelry', 'Shoe Stores', 'Accessories', 'Vintage & Consignment', 'Sporting Goods', 'Beer, Wine & Spirits', 'Department Stores', 'Bookstores', 'Electronics', 'Drugstores', 'Music & DVDs', 'Toy Stores', 'Tattoo', 'Eyewear & Opticians', 'Optometrists', 'Comic Books', 'Antiques', 'Gift Shops', 'Mobile Phones', 'Discount Store', 'Hardware Stores', 'Pet Stores', 'Appliances & Repair', 'Appliances', 'Vape Shops', 'Outlet Stores', 'Home & Garden', 'Building Supplies', 'Art Supplies', 'Thrift Stores', 'Hobby Shops', 'Musical Instruments & Teachers', 'Mattresses', 'Bike Repair/Maintenance', 'Books, Mags, Music & Video', 'Computers', 'Mobile Phone Accessories', 'Cosmetics & Beauty Supply', 'Eyelash Service', 'Hair Extensions', 'Hair Stylists', 'Waxing', 'Cosmetic Surgeons', 'Makeup Artists', 'Hair Loss Centers', 'Medical Spas', 'Nail Technicians', 'Hair Salons', 'Nail Salons', 'Massage', 'Day Spas', 'Barbers', 'Massage Therapy', 'Tattoo Removal', 'Piercing', 'Laser Hair Removal', 'Eyebrow Services', 'Permanent Makeup', 'Acne Treatment', 'Weight Loss Centers', 'Medical Supplies', 'Optometrists', 'Health Markets', 'Nutritionists', 'Physical Therapy', 'Dermatologists', 'Chiropractors', 'Hospitals', 'Acupuncture', 'Cryotherapy', 'Medical Centers', 'Sports Medicine', 'Alternative Medicine', 'Prenatal/Perinatal Care', 'Ophthalmologists', 'Internal Medicine', 'Allergists', 'Audiologist', 'Ear Nose & Throat', 'Allergists'],\n",
    "    'Home Services': ['Home Services', 'Local Services', 'Real Estate', 'Contractors', 'Apartments', 'Home Decor', 'Movers', 'Mattresses', 'Appliances & Repair', 'Appliances', 'Home & Garden', 'Building Supplies', 'Security Systems', 'Waterproofing', 'Insulation Installation', 'Pest Control', 'Heating & Air Conditioning/HVAC', 'Plumbing', 'Carpet Cleaning', 'Air Duct Cleaning', 'Home Inspectors', 'Electricians', 'Solar Installation', 'Solar Panel Cleaning', 'Windows Installation', 'Glass & Mirrors', 'Window Washing', 'Pressure Washers', 'Roofing', 'Gutter Services', 'Siding', 'Carpenters', 'Masonry/Concrete', 'Fireplace Services', 'Carpeting', 'Home Automation', 'Handyman', 'Painters', 'Landscape Architects', 'Irrigation', 'Fences & Gates', 'Pool & Hot Tub Service', 'Pool Cleaners', 'Tree Services', 'Septic Services', 'Water Purification Services', 'Oil Change Stations', 'Excavation Services', 'Snow Removal'],\n",
    "    'Beauty & Spas': [ 'Beauty & Spas', 'Hair Salons', 'Nail Salons', 'Hair Removal', 'Skin Care', 'Day Spas', 'Barbers', 'Massage', 'Waxing', 'Massage Therapy', 'Tattoo Removal', 'Piercing', 'Laser Hair Removal', 'Eyebrow Services', 'Permanent Makeup', 'Acne Treatment', 'Weight Loss Centers', 'Health Markets', 'Nutritionists', 'Physical Therapy', 'Dermatologists', 'Chiropractors', 'Medical Spas', 'Cosmetic Surgeons', 'Makeup Artists', 'Hair Loss Centers', 'Medical Supplies', 'Optometrists', 'Alternative Medicine', 'Prenatal/Perinatal Care', 'Ophthalmologists', 'Internal Medicine', 'Allergists', 'Audiologist', 'Ear Nose & Throat', 'Allergists'],\n",
    "    'Nightlife': ['Nightlife', 'Bars', 'Sports Bars', 'Pubs', 'Cocktail Bars', 'Beer Gardens', 'Wine Bars', 'Karaoke', 'Breweries', 'Dive Bars', 'Wine Tasting Room', 'Jazz & Blues', 'Tiki Bars', 'Bartenders', 'Distilleries'],\n",
    "    'Other': []\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize grouped category counts\n",
    "grouped_category_counts = {}\n",
    "\n",
    "# Iterate through businesses and update the grouped categories\n",
    "for business in businesses:\n",
    "    categories_str = business.get(\"categories\", '')\n",
    "    if categories_str:\n",
    "        categories = categories_str.split(', ')\n",
    "        for category in categories:\n",
    "            for group, group_categories in category_groups.items():\n",
    "                if category in group_categories:\n",
    "                        grouped_category_counts[group] = grouped_category_counts.get(group, 0) + 1\n",
    "                        business[\"type\"] = group\n",
    "                        businesses_dict[business[\"business_id\"]] = business\n",
    "                        break\n",
    "            else:\n",
    "                # If no matching category is found, assign the business to the \"Other\" category\n",
    "                grouped_category_counts[\"Other\"] = grouped_category_counts.get(\"Other\", 0) + 1\n",
    "                business[\"type\"] = \"Other\"\n",
    "                businesses_dict[business[\"business_id\"]] = business\n",
    "                        \n",
    "\n",
    "# Find the most frequent grouped categories\n",
    "grouped_category_counts = sorted(grouped_category_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "grouped_category_counts[:6]\n",
    "\n",
    "# Create a list of the most frequent grouped categories\n",
    "top_grouped_categories = [category[0] for category in grouped_category_counts[:6]]\n",
    "\n",
    "# print the top 5 most frequent grouped categories and their counts\n",
    "print(grouped_category_counts[:6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.pie([category[1] for category in category_counts])\n",
    "plt.title(\"Original Categories\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data for the pie chart\n",
    "labels = top_grouped_categories\n",
    "sizes = [count[1] for count in grouped_category_counts[:6]]\n",
    "\n",
    "# Create a pie chart\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140)\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that the pie is drawn as a circle.\n",
    "plt.title('Grouped Categories Distribution')\n",
    "\n",
    "# Show the pie chart\n",
    "plt.show()\n",
    "\n",
    "# print out the grouped categories and their counts \n",
    "grouped_category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the data to save for query processing\n",
    "\n",
    "# Remove the \"categories\" key from test business in business_dict\n",
    "for business in businesses_dict.values():\n",
    "    business.pop(\"categories\", None)\n",
    "    \n",
    "# Make it into a data frame\n",
    "business_df = pd.DataFrame(businesses_dict.values())\n",
    "business_df[\"type\"] = business_df[\"type\"].str.lower() # Make type lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f\"data/02_postprocessing/{'sample/' if SAMPLE else ''}businesses.csv\"\n",
    "with open(file_name, \"w\") as f:\n",
    "    business_df.to_csv(f, index=False, header=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read business JSON file \n",
    "with open(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}businesses.json\") as f:\n",
    "    business_df = pd.DataFrame([json.loads(line) for line in f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "custom_stop_words = [\",\", \"&\", \"-\", \"(\", \")\", \".\", \"'\", \"!\", \"?\", \":\", \";\", \"[\", \"]\", \"/\", \"I\", \"'ve\", \"'s\", \"n't\", \"a\", \"``\", \"also\", \"'ll\", \"$\", \"'d\", \" \"]\n",
    "# add numbers to the custom_stop_words list 1 to 100\n",
    "custom_stop_words.extend([str(i) for i in range(100)])\n",
    "# combine the stop_words and custom_stop_words lists and make it into a set\n",
    "all_stop_words = set(stopwords.words(\"english\") + custom_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract keywords from each business entry for category and name attributes using dictionary; make lowercase\n",
    "business_df[\"categories\"] = business_df[\"categories\"].str.lower()\n",
    "business_df[\"name\"] = business_df[\"name\"].str.lower()\n",
    "\n",
    "# make a new data frame for keywords from categories and name attributes\n",
    "# split the categories string into a list of words and remove stop words\n",
    "# if categories is None don't run\n",
    "if business_df[\"categories\"].isnull().values.any() == False:\n",
    "    business_df[\"categories\"] = business_df[\"categories\"].apply(lambda x: [word for word in re.split(\"\\W+\", x) if word not in all_stop_words])\n",
    "business_df[\"name\"] = business_df[\"name\"].apply(lambda x: [word for word in re.split(\"\\W+\", x) if word not in all_stop_words])\n",
    "business_keywords_df = business_df[[\"business_id\", \"name\", \"categories\"]].reset_index(drop=True)\n",
    "# combine the name and categories lists into a keywords list\n",
    "business_keywords_df[\"keywords\"] = business_keywords_df[\"name\"].astype(str) + business_keywords_df[\"categories\"].astype(str)\n",
    "# remove the name and categories columns\n",
    "business_keywords_df = business_keywords_df.drop(columns=[\"name\", \"categories\"])\n",
    "# explode the keywords list\n",
    "business_keywords_addition = business_keywords_df.explode(\"keywords\").reset_index(drop=True)\n",
    "# rename the column\n",
    "business_keywords_addition.rename(columns={\"keywords\": \"keyword\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read review JSON file\n",
    "with open(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}reviews.json\") as f:\n",
    "    review_df = pd.read_json(f, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the stop_words and custom_stop_words lists and make it into a set\n",
    "all_stop_words = set(stopwords.words(\"english\") + custom_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df[\"text\"] = review_df[\"text\"].str.lower() # make text lowercase\n",
    "# Make the text column a list by tokenizing it\n",
    "review_df[\"text\"] = review_df[\"text\"].apply(lambda x: [word for word in re.split('\\W+', x) if word not in all_stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new data frame for keywords\n",
    "review_keywords_df = review_df[[\"business_id\", \"text\"]].explode(\"text\").rename(columns={\"text\": \"keyword\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with keyword counts\n",
    "temp = review_keywords_df.groupby([\"business_id\", \"keyword\"]).size().reset_index(name=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each business id, get the top 10 keywords with the highest count\n",
    "top_keywords_per_business = (temp.groupby(\"business_id\")\n",
    "                             .apply(lambda x: x.nlargest(5, \"count\"))\n",
    "                             .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_keywords_per_business.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the business keywords in a csv file\n",
    "file_name = f\"data/02_postprocessing/{'sample/' if SAMPLE else ''}businesses_keywords.csv\"\n",
    "with open(file_name, \"w\") as f:\n",
    "    business_keywords.to_csv(f, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
