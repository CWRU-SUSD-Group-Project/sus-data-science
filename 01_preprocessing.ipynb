{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "_ = nltk.download(\"stopwords\", quiet=True)\n",
    "_ = nltk.download(\"punkt\", quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data/02_postprocessing direction if it does not exist\n",
    "if not os.path.exists(\"data/02_postprocessing\"):\n",
    "    os.makedirs(\"data/02_postprocessing\")\n",
    "# Create the data/02_postprocessing/sample directory if it does not exist\n",
    "if not os.path.exists(\"data/02_postprocessing/sample\"):\n",
    "    os.makedirs(\"data/02_postprocessing/sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silent_remove(filename):\n",
    "    try:\n",
    "        os.remove(filename)\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed so that it can be run on the sample data or the full data just by switching one variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to True to run the script on the sample data\n",
    "# Set this to False to run the script on the full data (takes much longer)\n",
    "SAMPLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section performs rating normalization (technically standardization) to all ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [!] 4 minutes to load\n",
    "with open(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}ratings.json\") as f:\n",
    "    ratings_original = [json.loads(line) for line in f]\n",
    "with open(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}users.json\") as f:\n",
    "    users_original = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings_dict = {}\n",
    "for rating in ratings_original:\n",
    "    user_id = rating[\"user_id\"]\n",
    "    if user_id not in user_ratings_dict.keys():\n",
    "        user_ratings_dict[user_id] = {\"rating_objs\": [rating], \"ratings\": [(rating[\"rating_id\"], rating[\"stars\"])]}\n",
    "    else:\n",
    "        user_ratings_dict[user_id][\"rating_objs\"].append(rating)\n",
    "        user_ratings_dict[user_id][\"ratings\"].append((rating[\"rating_id\"], rating[\"stars\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to determine the cut off for how many ratings a user should have before we\n",
    "# apply z-score normalization\n",
    "\n",
    "# This outputs the ratio between the number of ratings that would be standardized\n",
    "# and all ratings in the dataset\n",
    "\n",
    "cutoff = 5\n",
    "num_ratings = [len(user[\"ratings\"]) for user in user_ratings_dict.values()]\n",
    "rating_count = Counter(num_ratings)\n",
    "rating_counter_agg = [(tup[0], tup[1], tup[0] * tup[1]) for tup in rating_count.items()]\n",
    "ratio = sum([tup[2] for tup in rating_counter_agg if tup[0] >= cutoff]) / sum([tup[2] for tup in rating_counter_agg])\n",
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_not_standardized = []\n",
    "users_standardized = []\n",
    "for user_id, user_ratings in user_ratings_dict.items():\n",
    "    if (\n",
    "        len(user_ratings[\"ratings\"]) >= cutoff\n",
    "        and len(set(list(zip(*user_ratings[\"ratings\"]))[1])) >= 2\n",
    "    ):\n",
    "        users_standardized.append(user_id)\n",
    "        user_ratings[\"avg_rating\"] = statistics.mean(\n",
    "            list(zip(*user_ratings[\"ratings\"]))[1]\n",
    "        )\n",
    "        user_ratings[\"std_dev\"] = statistics.stdev(\n",
    "            list(zip(*user_ratings[\"ratings\"]))[1]\n",
    "        )\n",
    "        user_ratings[\"standardized_ratings\"] = [\n",
    "            (\n",
    "                rating[0],\n",
    "                (rating[1] - user_ratings[\"avg_rating\"]) / user_ratings[\"std_dev\"],\n",
    "            )\n",
    "            for rating in user_ratings[\"ratings\"]\n",
    "        ]\n",
    "    else:\n",
    "        users_not_standardized.append(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all ratings standardized by user\n",
    "user_standardized_ratings = [\n",
    "    rating\n",
    "    for user_ratings in [\n",
    "        user_rating\n",
    "        for user_rating in user_ratings_dict.values()\n",
    "        if \"standardized_ratings\" in user_rating.keys()\n",
    "    ]\n",
    "    for rating in user_ratings[\"standardized_ratings\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize all other ratings with respect to each other\n",
    "not_standardized_ratings = [\n",
    "    rating\n",
    "    for user_ratings in [\n",
    "        user_ratings_dict[user_id] for user_id in users_not_standardized\n",
    "    ]\n",
    "    for rating in user_ratings[\"ratings\"]\n",
    "]\n",
    "mean = statistics.mean(list(zip(*not_standardized_ratings))[1])\n",
    "std_dev = statistics.stdev(list(zip(*not_standardized_ratings))[1])\n",
    "pool_standardized_ratings = [\n",
    "    (rating[0], (rating[1] - mean) / std_dev) for rating in not_standardized_ratings\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = {rating[\"rating_id\"]: rating for rating in ratings_original}\n",
    "for rating in user_standardized_ratings + pool_standardized_ratings:\n",
    "    ratings[rating[0]][\"standardized_rating\"] = rating[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a min-max normalized standardized rating for each rating object\n",
    "# The attribute will be called \"norm_std_rating\"\n",
    "\n",
    "rating_df = pd.DataFrame(ratings_original).drop(\n",
    "    columns=[\"business_id\", \"rating_id\"]\n",
    ")\n",
    "max_std_rating = rating_df[\"standardized_rating\"].max()\n",
    "min_std_rating = rating_df[\"standardized_rating\"].min()\n",
    "\n",
    "rating_df[\"norm_std_rating\"] = (\n",
    "    (rating_df[\"standardized_rating\"] - min_std_rating) /\n",
    "    (max_std_rating - min_std_rating)\n",
    ")\n",
    "rating_df[\"norm_std_rating\"] = (rating_df[\"norm_std_rating\"] * 4) + 1\n",
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make standardized_rating vs norm_std_rating a yes-no attribute\n",
    "# Make it wide-form data\n",
    "rating_df_wide_list = []\n",
    "for index, row in rating_df.iterrows():\n",
    "    rating_df_wide_list.append({\n",
    "        \"user_id\": row[\"user_id\"],\n",
    "        \"standardized\": \"Yes\",\n",
    "        \"rating\": row[\"norm_std_rating\"],\n",
    "    })\n",
    "    rating_df_wide_list.append({\n",
    "        \"user_id\": row[\"user_id\"],\n",
    "        \"standardized\": \"No\",\n",
    "        \"rating\": row[\"stars\"],\n",
    "    })\n",
    "rating_df_wide = pd.DataFrame(rating_df_wide_list)\n",
    "rating_df_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the user with the max average rating and the user with the min average rating\n",
    "\n",
    "graphing_cutoff = 20\n",
    "graph_pool = [\n",
    "    user\n",
    "    for user in users_standardized\n",
    "    if len(user_ratings_dict[user][\"ratings\"]) >= graphing_cutoff\n",
    "]\n",
    "print(f\"Narrowed down to {len(graph_pool) * 100 / len(users_standardized)}%\")\n",
    "\n",
    "max_avg_user = max(users_standardized, key=lambda x: user_ratings_dict[x][\"avg_rating\"])\n",
    "min_avg_user = min(users_standardized, key=lambda x: user_ratings_dict[x][\"avg_rating\"])\n",
    "max_std_dev_user = max(\n",
    "    users_standardized, key=lambda x: user_ratings_dict[x][\"std_dev\"]\n",
    ")\n",
    "min_std_dev_user = min(\n",
    "    list(set(users_standardized) - set([max_avg_user])), key=lambda x: user_ratings_dict[x][\"std_dev\"]\n",
    ")\n",
    "print(f\"Found 4 users: {max_avg_user}, {min_avg_user}, {max_std_dev_user}, {min_std_dev_user}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_df = rating_df_wide.copy()\n",
    "graph_df[\"user_id\"] = graph_df[\"user_id\"].map({\n",
    "    max_avg_user: \"max_avg\",\n",
    "    min_avg_user: \"min_avg\",\n",
    "    max_std_dev_user: \"max_std_dev\",\n",
    "    min_std_dev_user: \"min_std_dev\",\n",
    "}).fillna(\"other\")\n",
    "graph_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.displot(\n",
    "    data=graph_df.loc[graph_df[\"user_id\"] != \"other\"],\n",
    "    kind=\"hist\",\n",
    "    x=\"rating\",\n",
    "    hue=\"standardized\",\n",
    "    col=\"user_id\",\n",
    "    col_order=[\"max_avg\", \"min_avg\", \"max_std_dev\", \"min_std_dev\"],\n",
    "    col_wrap=2,\n",
    "    stat=\"probability\",\n",
    "    common_norm=False,\n",
    "    bins=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.displot(\n",
    "    data=graph_df,\n",
    "    kind=\"hist\",\n",
    "    x=\"rating\",\n",
    "    hue=\"standardized\",\n",
    "    stat=\"probability\",\n",
    "    bins=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f\"data/02_postprocessing/{'sample/' if SAMPLE else ''}ratings.csv\"\n",
    "silent_remove(file_name)\n",
    "with open(file_name, \"w\") as f:\n",
    "    rating_df.to_csv(f, index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Businesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories >> Type, Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}businesses.json\") as f:\n",
    "    businesses = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count most frequently category occurrences in businesses.json\n",
    "category_counts = {}\n",
    "for business in businesses:\n",
    "    categories_str = business.get(\"categories\", '')\n",
    "    if categories_str:\n",
    "        categories = categories_str.split(', ')\n",
    "        for category in categories:\n",
    "            category_counts[category] = category_counts.get(category, 0) + 1\n",
    "\n",
    "# Find the most frequent categories\n",
    "category_counts = sorted(category_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "category_counts[:1000]\n",
    "\n",
    "# Create a list of the most frequent categories\n",
    "top_categories = [category[0] for category in category_counts[:1000]]\n",
    "\n",
    "# print the top 500 most frequent categories\n",
    "print(top_categories)\n",
    "\n",
    "# Keep only the businesses that have at least one of the top 5 categories using a dictionary and create a new attribute \"type\" for each business that states which of the top 5 categories it belongs to\n",
    "businesses_dict = {}\n",
    "for business in businesses:\n",
    "    categories_str = business.get(\"categories\", '')\n",
    "    if categories_str:\n",
    "        categories = categories_str.split(', ')\n",
    "        for category in categories:\n",
    "            if category in top_categories:\n",
    "                business[\"type\"] = category\n",
    "                businesses_dict[business[\"business_id\"]] = business\n",
    "                break\n",
    "        else:\n",
    "            # If no matching category is found, assign the business to the \"Other\" category\n",
    "            business[\"type\"] = \"Other\"\n",
    "            businesses_dict[business[\"business_id\"]] = business\n",
    "\n",
    "# Define category grouping based on similarity\n",
    "category_groups = {\n",
    "    'Restaurants': ['Restaurants','Food', 'Breakfast & Brunch', 'Fast Food', 'Burgers', 'Pizza', 'Sandwiches', 'American (Traditional)', 'American (New)', 'Mexican', 'Chicken Wings', 'Salad', 'Chinese', 'Cafes', 'Sushi Bars', 'Barbeque', 'Southern', 'Japanese', 'Steakhouses', 'Juice Bars & Smoothies', 'Asian Fusion', 'Diners', 'Tex-Mex', 'Thai', 'Mediterranean', 'Indian', 'Vietnamese', 'Cajun/Creole', 'Latin American', 'Cuban', 'Puerto Rican', 'Caribbean', 'Japanese', 'Spanish', 'Korean', 'French', 'Halal', 'Mongolian', 'Canadian (New)', 'Filipino', 'Greek', 'Brazilian', 'Argentine', 'Hawaiian', 'Afghan', 'Indonesian', 'German', 'Ramen', 'Poke', 'Hot Pot', 'German', 'Pakistani', 'Uzbek', 'Persian/Iranian', 'Russian', 'Burmese', 'New Mexican Cuisine'],\n",
    "    'Shopping': ['Shopping', 'Fashion', 'Specialty Food', 'Bakeries', 'Grocery', 'Flowers & Gifts', 'Furniture Stores', 'Jewelry', 'Shoe Stores', 'Accessories', 'Vintage & Consignment', 'Sporting Goods', 'Beer, Wine & Spirits', 'Department Stores', 'Bookstores', 'Electronics', 'Drugstores', 'Music & DVDs', 'Toy Stores', 'Tattoo', 'Eyewear & Opticians', 'Optometrists', 'Comic Books', 'Antiques', 'Gift Shops', 'Mobile Phones', 'Discount Store', 'Hardware Stores', 'Pet Stores', 'Appliances & Repair', 'Appliances', 'Vape Shops', 'Outlet Stores', 'Home & Garden', 'Building Supplies', 'Art Supplies', 'Thrift Stores', 'Hobby Shops', 'Musical Instruments & Teachers', 'Mattresses', 'Bike Repair/Maintenance', 'Books, Mags, Music & Video', 'Computers', 'Mobile Phone Accessories', 'Cosmetics & Beauty Supply', 'Eyelash Service', 'Hair Extensions', 'Hair Stylists', 'Waxing', 'Cosmetic Surgeons', 'Makeup Artists', 'Hair Loss Centers', 'Medical Spas', 'Nail Technicians', 'Hair Salons', 'Nail Salons', 'Massage', 'Day Spas', 'Barbers', 'Massage Therapy', 'Tattoo Removal', 'Piercing', 'Laser Hair Removal', 'Eyebrow Services', 'Permanent Makeup', 'Acne Treatment', 'Weight Loss Centers', 'Medical Supplies', 'Optometrists', 'Health Markets', 'Nutritionists', 'Physical Therapy', 'Dermatologists', 'Chiropractors', 'Hospitals', 'Acupuncture', 'Cryotherapy', 'Medical Centers', 'Sports Medicine', 'Alternative Medicine', 'Prenatal/Perinatal Care', 'Ophthalmologists', 'Internal Medicine', 'Allergists', 'Audiologist', 'Ear Nose & Throat', 'Allergists'],\n",
    "    'Home Services': ['Home Services', 'Local Services', 'Real Estate', 'Contractors', 'Apartments', 'Home Decor', 'Movers', 'Mattresses', 'Appliances & Repair', 'Appliances', 'Home & Garden', 'Building Supplies', 'Security Systems', 'Waterproofing', 'Insulation Installation', 'Pest Control', 'Heating & Air Conditioning/HVAC', 'Plumbing', 'Carpet Cleaning', 'Air Duct Cleaning', 'Home Inspectors', 'Electricians', 'Solar Installation', 'Solar Panel Cleaning', 'Windows Installation', 'Glass & Mirrors', 'Window Washing', 'Pressure Washers', 'Roofing', 'Gutter Services', 'Siding', 'Carpenters', 'Masonry/Concrete', 'Fireplace Services', 'Carpeting', 'Home Automation', 'Handyman', 'Painters', 'Landscape Architects', 'Irrigation', 'Fences & Gates', 'Pool & Hot Tub Service', 'Pool Cleaners', 'Tree Services', 'Septic Services', 'Water Purification Services', 'Oil Change Stations', 'Excavation Services', 'Snow Removal'],\n",
    "    'Beauty & Spas': [ 'Beauty & Spas', 'Hair Salons', 'Nail Salons', 'Hair Removal', 'Skin Care', 'Day Spas', 'Barbers', 'Massage', 'Waxing', 'Massage Therapy', 'Tattoo Removal', 'Piercing', 'Laser Hair Removal', 'Eyebrow Services', 'Permanent Makeup', 'Acne Treatment', 'Weight Loss Centers', 'Health Markets', 'Nutritionists', 'Physical Therapy', 'Dermatologists', 'Chiropractors', 'Medical Spas', 'Cosmetic Surgeons', 'Makeup Artists', 'Hair Loss Centers', 'Medical Supplies', 'Optometrists', 'Alternative Medicine', 'Prenatal/Perinatal Care', 'Ophthalmologists', 'Internal Medicine', 'Allergists', 'Audiologist', 'Ear Nose & Throat', 'Allergists'],\n",
    "    'Nightlife': ['Nightlife', 'Bars', 'Sports Bars', 'Pubs', 'Cocktail Bars', 'Beer Gardens', 'Wine Bars', 'Karaoke', 'Breweries', 'Dive Bars', 'Wine Tasting Room', 'Jazz & Blues', 'Tiki Bars', 'Bartenders', 'Distilleries'],\n",
    "    'Other': []\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize grouped category counts\n",
    "grouped_category_counts = {}\n",
    "\n",
    "# Iterate through businesses and update the grouped categories\n",
    "for business in businesses:\n",
    "    categories_str = business.get(\"categories\", '')\n",
    "    if categories_str:\n",
    "        categories = categories_str.split(', ')\n",
    "        for category in categories:\n",
    "            for group, group_categories in category_groups.items():\n",
    "                if category in group_categories:\n",
    "                        grouped_category_counts[group] = grouped_category_counts.get(group, 0) + 1\n",
    "                        business[\"type\"] = group\n",
    "                        businesses_dict[business[\"business_id\"]] = business\n",
    "                        break\n",
    "            else:\n",
    "                # If no matching category is found, assign the business to the \"Other\" category\n",
    "                grouped_category_counts[\"Other\"] = grouped_category_counts.get(\"Other\", 0) + 1\n",
    "                business[\"type\"] = \"Other\"\n",
    "                businesses_dict[business[\"business_id\"]] = business\n",
    "                        \n",
    "\n",
    "# Find the most frequent grouped categories\n",
    "grouped_category_counts = sorted(grouped_category_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "grouped_category_counts[:6]\n",
    "\n",
    "# Create a list of the most frequent grouped categories\n",
    "top_grouped_categories = [category[0] for category in grouped_category_counts[:6]]\n",
    "\n",
    "# print the top 5 most frequent grouped categories and their counts\n",
    "print(grouped_category_counts[:6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.pie([category[1] for category in category_counts])\n",
    "plt.title(\"Original Categories\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data for the pie chart\n",
    "labels = top_grouped_categories\n",
    "sizes = [count[1] for count in grouped_category_counts[:6]]\n",
    "\n",
    "# Create a pie chart\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140)\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that the pie is drawn as a circle.\n",
    "plt.title('Grouped Categories Distribution')\n",
    "\n",
    "# Show the pie chart\n",
    "plt.show()\n",
    "\n",
    "# print out the grouped categories and their counts \n",
    "grouped_category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the data to save for query processing\n",
    "\n",
    "# Remove the \"categories\" key from test business in business_dict\n",
    "for business in businesses_dict.values():\n",
    "    business.pop(\"categories\", None)\n",
    "    \n",
    "# Make it into a data frame\n",
    "business_df = pd.DataFrame(businesses_dict.values())\n",
    "business_df[\"type\"] = business_df[\"type\"].str.lower() # Make type lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f\"data/02_postprocessing/{'sample/' if SAMPLE else ''}businesses.csv\"\n",
    "with open(file_name, \"w\") as f:\n",
    "    business_df.to_csv(f, index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read business JSON file\n",
    "with open(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}businesses.json\") as f:\n",
    "    businesses = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "custom_stop_words = [\",\", \"&\", \"-\", \"(\", \")\", \".\", \"'\", \"!\", \"?\", \":\", \";\", \"[\", \"]\", \"/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract keywords from each business entry for category and name attributes using dictionary\n",
    "business_keywords = {}\n",
    "for business in businesses:\n",
    "    business_keywords[business[\"business_id\"]] = {\"category\": [], \"name\": []}\n",
    "    for word in word_tokenize(business[\"categories\"]):\n",
    "        if word not in stop_words and word not in custom_stop_words:\n",
    "            business_keywords[business[\"business_id\"]][\"category\"].append(word)\n",
    "    for word in word_tokenize(business[\"name\"]):\n",
    "        if word not in stop_words and word not in custom_stop_words:\n",
    "            business_keywords[business[\"business_id\"]][\"name\"].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read review JSON file\n",
    "with open(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}reviews.json\") as f:\n",
    "    reviews = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract keywords from each review entry for text attribute using dictionary\n",
    "review_keywords = {}\n",
    "for review in reviews:\n",
    "    review_keywords[review[\"review_id\"]] = []\n",
    "    for word in word_tokenize(review[\"text\"]):\n",
    "        if word not in stop_words and word not in custom_stop_words:\n",
    "            review_keywords[review[\"review_id\"]].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of business_id to a list of review_ids\n",
    "business_review_dict = {}\n",
    "for review in reviews:\n",
    "    if review[\"business_id\"] not in business_review_dict.keys():\n",
    "        business_review_dict[review[\"business_id\"]] = [review[\"review_id\"]]\n",
    "    else:\n",
    "        business_review_dict[review[\"business_id\"]].append(review[\"review_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine keywords from all reviews, category, and name for each business\n",
    "# some businesses do not have any reviews, so we only combine category and name keywords for those businesses using dictionary\n",
    "business_keywords_combined = {}\n",
    "for business in businesses:\n",
    "    business_keywords_combined[business[\"business_id\"]] = []\n",
    "    if business[\"business_id\"] in business_review_dict.keys():\n",
    "        for review_id in business_review_dict[business[\"business_id\"]]:\n",
    "            business_keywords_combined[business[\"business_id\"]] += review_keywords[review_id]\n",
    "    business_keywords_combined[business[\"business_id\"]] += business_keywords[business[\"business_id\"]][\"category\"]\n",
    "    business_keywords_combined[business[\"business_id\"]] += business_keywords[business[\"business_id\"]][\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the keywords for each business with their name\n",
    "for business in businesses:\n",
    "    print(business[\"name\"] + \": \")\n",
    "    print(business_keywords_combined[business[\"business_id\"]])\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
