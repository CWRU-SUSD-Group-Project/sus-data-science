{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "_ = nltk.download(\"stopwords\", quiet=True)\n",
    "_ = nltk.download(\"punkt\", quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data/02_postprocessing direction if it does not exist\n",
    "if not os.path.exists(\"data/02_postprocessing\"):\n",
    "    os.makedirs(\"data/02_postprocessing\")\n",
    "# Create the data/02_postprocessing/sample directory if it does not exist\n",
    "if not os.path.exists(\"data/02_postprocessing/sample\"):\n",
    "    os.makedirs(\"data/02_postprocessing/sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silent_remove(filename):\n",
    "    try:\n",
    "        os.remove(filename)\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed so that it can be run on the sample data or the full data just by switching one variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to True to run the script on the sample data\n",
    "# Set this to False to run the script on the full data (takes much longer)\n",
    "SAMPLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section performs rating normalization (technically standardization) to all ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ratings and users data\n",
    "file_name = f\"data/01_cleaned/{'sample/' if SAMPLE else ''}ratings.csv\"\n",
    "ratings = pd.read_csv(file_name, header=0)\n",
    "file_name = f\"data/01_cleaned/{'sample/' if SAMPLE else ''}users.csv\"\n",
    "users = pd.read_csv(file_name, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index on the \"user_id\" and \"rating_id\" columns\n",
    "ratings = ratings.set_index([\"user_id\", \"rating_id\"])\n",
    "# Index on the \"user_id\" column for the users data\n",
    "users = users.set_index(\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of ratings for each user_id in the ratings data frame\n",
    "user_ratings = ratings.groupby(\"user_id\").agg(\n",
    "    num_ratings = pd.NamedAgg(column=\"stars\", aggfunc=\"count\"),\n",
    "    mean_rating = pd.NamedAgg(column=\"stars\", aggfunc=\"mean\"),\n",
    "    std_rating = pd.NamedAgg(column=\"stars\", aggfunc=\"std\"),\n",
    ")\n",
    "user_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a \"num_ratings\" to the users data frame by joining the users and user_ratings data frames\n",
    "users = users.join(user_ratings, on=\"user_id\", how=\"left\")\n",
    "# Set null values to 0\n",
    "users[\"num_ratings\"].fillna(0, inplace=True)\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a \"above_cutoff\" column to the users data frame\n",
    "# This column is True if the user has more than \"cutoff\" ratings in the ratings data frame\n",
    "cutoff = 5 # TODO justify this\n",
    "users[\"above_cutoff\"] = users[\"num_ratings\"] > cutoff\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings[\"std_rating\"] = np.NaN\n",
    "cutoff_users = users[users[\"above_cutoff\"]]\n",
    "ratings.loc[cutoff_users.index, \"std_rating\"] = (\n",
    "    ratings.loc[cutoff_users.index, \"stars\"] - cutoff_users[\"mean_rating\"]\n",
    ") / cutoff_users[\"std_rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.loc[cutoff_users.index].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_users = users[~users[\"above_cutoff\"]]\n",
    "other_mean = ratings.loc[other_users.index, \"stars\"].mean()\n",
    "other_std = ratings.loc[other_users.index, \"stars\"].std()\n",
    "ratings.loc[other_users.index, \"std_rating\"] = (\n",
    "    ratings.loc[other_users.index, \"stars\"] - other_mean\n",
    ") / other_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.loc[other_users.index].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_std = ratings[\"std_rating\"].min()\n",
    "max_std = ratings[\"std_rating\"].max()\n",
    "ratings[\"norm_std_rating\"] = (((ratings[\"std_rating\"] - min_std) / (max_std - min_std)) * 4) + 1\n",
    "ratings.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reindexed_ratings = ratings.reset_index()\n",
    "reindexed_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f\"data/02_postprocessing/{'sample/' if SAMPLE else ''}ratings.csv\"\n",
    "with open(file_name, \"w\") as f:\n",
    "    reindexed_ratings.to_csv(f, index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Businesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories >> Type, Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}businesses.csv\") as f:\n",
    "    businesses = pd.read_csv(f, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define category grouping based on similarity\n",
    "category_groups = {\n",
    "    \"Restaurants\": [\n",
    "        \"Restaurants\",\n",
    "        \"Food\",\n",
    "        \"Breakfast & Brunch\",\n",
    "        \"Fast Food\",\n",
    "        \"Burgers\",\n",
    "        \"Pizza\",\n",
    "        \"Sandwiches\",\n",
    "        \"American (Traditional)\",\n",
    "        \"American (New)\",\n",
    "        \"Mexican\",\n",
    "        \"Chicken Wings\",\n",
    "        \"Salad\",\n",
    "        \"Chinese\",\n",
    "        \"Cafes\",\n",
    "        \"Sushi Bars\",\n",
    "        \"Barbeque\",\n",
    "        \"Southern\",\n",
    "        \"Japanese\",\n",
    "        \"Steakhouses\",\n",
    "        \"Juice Bars & Smoothies\",\n",
    "        \"Asian Fusion\",\n",
    "        \"Diners\",\n",
    "        \"Tex-Mex\",\n",
    "        \"Thai\",\n",
    "        \"Mediterranean\",\n",
    "        \"Indian\",\n",
    "        \"Vietnamese\",\n",
    "        \"Cajun/Creole\",\n",
    "        \"Latin American\",\n",
    "        \"Cuban\",\n",
    "        \"Puerto Rican\",\n",
    "        \"Caribbean\",\n",
    "        \"Japanese\",\n",
    "        \"Spanish\",\n",
    "        \"Korean\",\n",
    "        \"French\",\n",
    "        \"Halal\",\n",
    "        \"Mongolian\",\n",
    "        \"Canadian (New)\",\n",
    "        \"Filipino\",\n",
    "        \"Greek\",\n",
    "        \"Brazilian\",\n",
    "        \"Argentine\",\n",
    "        \"Hawaiian\",\n",
    "        \"Afghan\",\n",
    "        \"Indonesian\",\n",
    "        \"German\",\n",
    "        \"Ramen\",\n",
    "        \"Poke\",\n",
    "        \"Hot Pot\",\n",
    "        \"German\",\n",
    "        \"Pakistani\",\n",
    "        \"Uzbek\",\n",
    "        \"Persian/Iranian\",\n",
    "        \"Russian\",\n",
    "        \"Burmese\",\n",
    "        \"New Mexican Cuisine\",\n",
    "    ],\n",
    "    \"Shopping\": [\n",
    "        \"Shopping\",\n",
    "        \"Fashion\",\n",
    "        \"Specialty Food\",\n",
    "        \"Bakeries\",\n",
    "        \"Grocery\",\n",
    "        \"Flowers & Gifts\",\n",
    "        \"Furniture Stores\",\n",
    "        \"Jewelry\",\n",
    "        \"Shoe Stores\",\n",
    "        \"Accessories\",\n",
    "        \"Vintage & Consignment\",\n",
    "        \"Sporting Goods\",\n",
    "        \"Beer, Wine & Spirits\",\n",
    "        \"Department Stores\",\n",
    "        \"Bookstores\",\n",
    "        \"Electronics\",\n",
    "        \"Drugstores\",\n",
    "        \"Music & DVDs\",\n",
    "        \"Toy Stores\",\n",
    "        \"Tattoo\",\n",
    "        \"Eyewear & Opticians\",\n",
    "        \"Optometrists\",\n",
    "        \"Comic Books\",\n",
    "        \"Antiques\",\n",
    "        \"Gift Shops\",\n",
    "        \"Mobile Phones\",\n",
    "        \"Discount Store\",\n",
    "        \"Hardware Stores\",\n",
    "        \"Pet Stores\",\n",
    "        \"Appliances & Repair\",\n",
    "        \"Appliances\",\n",
    "        \"Vape Shops\",\n",
    "        \"Outlet Stores\",\n",
    "        \"Home & Garden\",\n",
    "        \"Building Supplies\",\n",
    "        \"Art Supplies\",\n",
    "        \"Thrift Stores\",\n",
    "        \"Hobby Shops\",\n",
    "        \"Musical Instruments & Teachers\",\n",
    "        \"Mattresses\",\n",
    "        \"Bike Repair/Maintenance\",\n",
    "        \"Books, Mags, Music & Video\",\n",
    "        \"Computers\",\n",
    "        \"Mobile Phone Accessories\",\n",
    "        \"Cosmetics & Beauty Supply\",\n",
    "        \"Eyelash Service\",\n",
    "        \"Hair Extensions\",\n",
    "        \"Hair Stylists\",\n",
    "        \"Waxing\",\n",
    "        \"Cosmetic Surgeons\",\n",
    "        \"Makeup Artists\",\n",
    "        \"Hair Loss Centers\",\n",
    "        \"Medical Spas\",\n",
    "        \"Nail Technicians\",\n",
    "        \"Hair Salons\",\n",
    "        \"Nail Salons\",\n",
    "        \"Massage\",\n",
    "        \"Day Spas\",\n",
    "        \"Barbers\",\n",
    "        \"Massage Therapy\",\n",
    "        \"Tattoo Removal\",\n",
    "        \"Piercing\",\n",
    "        \"Laser Hair Removal\",\n",
    "        \"Eyebrow Services\",\n",
    "        \"Permanent Makeup\",\n",
    "        \"Acne Treatment\",\n",
    "        \"Weight Loss Centers\",\n",
    "        \"Medical Supplies\",\n",
    "        \"Optometrists\",\n",
    "        \"Health Markets\",\n",
    "        \"Nutritionists\",\n",
    "        \"Physical Therapy\",\n",
    "        \"Dermatologists\",\n",
    "        \"Chiropractors\",\n",
    "        \"Hospitals\",\n",
    "        \"Acupuncture\",\n",
    "        \"Cryotherapy\",\n",
    "        \"Medical Centers\",\n",
    "        \"Sports Medicine\",\n",
    "        \"Alternative Medicine\",\n",
    "        \"Prenatal/Perinatal Care\",\n",
    "        \"Ophthalmologists\",\n",
    "        \"Internal Medicine\",\n",
    "        \"Allergists\",\n",
    "        \"Audiologist\",\n",
    "        \"Ear Nose & Throat\",\n",
    "        \"Allergists\",\n",
    "    ],\n",
    "    \"Home Services\": [\n",
    "        \"Home Services\",\n",
    "        \"Local Services\",\n",
    "        \"Real Estate\",\n",
    "        \"Contractors\",\n",
    "        \"Apartments\",\n",
    "        \"Home Decor\",\n",
    "        \"Movers\",\n",
    "        \"Mattresses\",\n",
    "        \"Appliances & Repair\",\n",
    "        \"Appliances\",\n",
    "        \"Home & Garden\",\n",
    "        \"Building Supplies\",\n",
    "        \"Security Systems\",\n",
    "        \"Waterproofing\",\n",
    "        \"Insulation Installation\",\n",
    "        \"Pest Control\",\n",
    "        \"Heating & Air Conditioning/HVAC\",\n",
    "        \"Plumbing\",\n",
    "        \"Carpet Cleaning\",\n",
    "        \"Air Duct Cleaning\",\n",
    "        \"Home Inspectors\",\n",
    "        \"Electricians\",\n",
    "        \"Solar Installation\",\n",
    "        \"Solar Panel Cleaning\",\n",
    "        \"Windows Installation\",\n",
    "        \"Glass & Mirrors\",\n",
    "        \"Window Washing\",\n",
    "        \"Pressure Washers\",\n",
    "        \"Roofing\",\n",
    "        \"Gutter Services\",\n",
    "        \"Siding\",\n",
    "        \"Carpenters\",\n",
    "        \"Masonry/Concrete\",\n",
    "        \"Fireplace Services\",\n",
    "        \"Carpeting\",\n",
    "        \"Home Automation\",\n",
    "        \"Handyman\",\n",
    "        \"Painters\",\n",
    "        \"Landscape Architects\",\n",
    "        \"Irrigation\",\n",
    "        \"Fences & Gates\",\n",
    "        \"Pool & Hot Tub Service\",\n",
    "        \"Pool Cleaners\",\n",
    "        \"Tree Services\",\n",
    "        \"Septic Services\",\n",
    "        \"Water Purification Services\",\n",
    "        \"Oil Change Stations\",\n",
    "        \"Excavation Services\",\n",
    "        \"Snow Removal\",\n",
    "    ],\n",
    "    \"Beauty & Spas\": [\n",
    "        \"Beauty & Spas\",\n",
    "        \"Hair Salons\",\n",
    "        \"Nail Salons\",\n",
    "        \"Hair Removal\",\n",
    "        \"Skin Care\",\n",
    "        \"Day Spas\",\n",
    "        \"Barbers\",\n",
    "        \"Massage\",\n",
    "        \"Waxing\",\n",
    "        \"Massage Therapy\",\n",
    "        \"Tattoo Removal\",\n",
    "        \"Piercing\",\n",
    "        \"Laser Hair Removal\",\n",
    "        \"Eyebrow Services\",\n",
    "        \"Permanent Makeup\",\n",
    "        \"Acne Treatment\",\n",
    "        \"Weight Loss Centers\",\n",
    "        \"Health Markets\",\n",
    "        \"Nutritionists\",\n",
    "        \"Physical Therapy\",\n",
    "        \"Dermatologists\",\n",
    "        \"Chiropractors\",\n",
    "        \"Medical Spas\",\n",
    "        \"Cosmetic Surgeons\",\n",
    "        \"Makeup Artists\",\n",
    "        \"Hair Loss Centers\",\n",
    "        \"Medical Supplies\",\n",
    "        \"Optometrists\",\n",
    "        \"Alternative Medicine\",\n",
    "        \"Prenatal/Perinatal Care\",\n",
    "        \"Ophthalmologists\",\n",
    "        \"Internal Medicine\",\n",
    "        \"Allergists\",\n",
    "        \"Audiologist\",\n",
    "        \"Ear Nose & Throat\",\n",
    "        \"Allergists\",\n",
    "    ],\n",
    "    \"Nightlife\": [\n",
    "        \"Nightlife\",\n",
    "        \"Bars\",\n",
    "        \"Sports Bars\",\n",
    "        \"Pubs\",\n",
    "        \"Cocktail Bars\",\n",
    "        \"Beer Gardens\",\n",
    "        \"Wine Bars\",\n",
    "        \"Karaoke\",\n",
    "        \"Breweries\",\n",
    "        \"Dive Bars\",\n",
    "        \"Wine Tasting Room\",\n",
    "        \"Jazz & Blues\",\n",
    "        \"Tiki Bars\",\n",
    "        \"Bartenders\",\n",
    "        \"Distilleries\",\n",
    "    ],\n",
    "    \"Other\": [],\n",
    "}\n",
    "# Make the lists into sets\n",
    "for key in category_groups.keys():\n",
    "    category_groups[key] = set([category.lower() for category in category_groups[key]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make category a list\n",
    "businesses[\"categories\"] = businesses[\"categories\"].apply(\n",
    "    lambda x: x.split(\", \") if type(x) == str else []\n",
    ")\n",
    "# Make category lowercase\n",
    "businesses[\"categories\"] = businesses[\"categories\"].apply(\n",
    "    lambda x: set([category.lower() for category in x])\n",
    ")\n",
    "# Map according to the category_groups mapping\n",
    "businesses[\"categories\"] = businesses[\"categories\"].apply(\n",
    "    lambda x: [\n",
    "        cat_name\n",
    "        for cat_name, cat_values in category_groups.items()\n",
    "        if len(cat_values.intersection(x)) > 0\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Pick the top category according to the following order of preference:\n",
    "#   Restaurants > Shopping > Home Services > Beauty & Spas > Nightlife > Other\n",
    "def category_sort(category) -> int:\n",
    "    return [\n",
    "        \"Restaurants\",\n",
    "        \"Shopping\",\n",
    "        \"Home Services\",\n",
    "        \"Beauty & Spas\",\n",
    "        \"Nightlife\",\n",
    "        \"Other\",\n",
    "    ].index(category)\n",
    "\n",
    "\n",
    "businesses[\"categories\"] = businesses[\"categories\"].apply(\n",
    "    lambda x: sorted(list(x), key=category_sort)[0] if len(x) > 0 else \"Other\"\n",
    ")\n",
    "# Rename category to type\n",
    "businesses.rename(columns={\"categories\": \"type\"}, inplace=True)\n",
    "businesses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f\"data/02_postprocessing/{'sample/' if SAMPLE else ''}businesses.csv\"\n",
    "with open(file_name, \"w\") as f:\n",
    "    businesses.to_csv(f, index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining tokenizing specifications\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "custom_stop_words = [\",\", \"&\", \"-\", \"(\", \")\", \".\", \"'\", \"!\", \"?\", \":\", \";\", \"[\", \"]\", \"/\", \"I\", \"'ve\", \"'s\", \"n't\", \"a\", \"``\", \"also\", \"'ll\", \"$\", \"'d\", \" \"]\n",
    "# add numbers to the custom_stop_words list 1 to 100\n",
    "custom_stop_words.extend([str(i) for i in range(100)])\n",
    "# combine the stop_words and custom_stop_words lists and make it into a set\n",
    "all_stop_words = set(stopwords.words(\"english\") + custom_stop_words)\n",
    "\n",
    "# Tokenizing function\n",
    "def tokenize(text):\n",
    "    if text is None or type(text) != str:\n",
    "        return []\n",
    "    return [word.lower() for word in re.split('\\W+', text) if word not in all_stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read business JSON file \n",
    "with open(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}businesses.csv\") as f:\n",
    "    business_df = pd.read_csv(f, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract keywords from each business entry for category and name attributes using dictionary; make lowercase\n",
    "business_df[\"categories\"] = business_df[\"categories\"].str.lower()\n",
    "business_df[\"name\"] = business_df[\"name\"].str.lower()\n",
    "\n",
    "# make a new data frame for keywords from categories and name attributes\n",
    "# split the categories string into a list of words and remove stop words\n",
    "# if categories is None don't run\n",
    "business_df[\"categories\"] = business_df[\"categories\"].apply(tokenize)\n",
    "business_df[\"name\"] = business_df[\"name\"].apply(tokenize)\n",
    "business_keywords_df = business_df[[\"business_id\", \"name\", \"categories\"]].reset_index(drop=True)\n",
    "# combine the name and categories lists into a keywords list\n",
    "business_keywords_df[\"keywords\"] = business_keywords_df[\"name\"] + business_keywords_df[\"categories\"]\n",
    "# remove the name and categories columns\n",
    "business_keywords_df = business_keywords_df.drop(columns=[\"name\", \"categories\"])\n",
    "# explode the keywords list\n",
    "business_keywords_addition = business_keywords_df.explode(\"keywords\").reset_index(drop=True)\n",
    "# rename the column\n",
    "business_keywords_addition.rename(columns={\"keywords\": \"keyword\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read review JSON file\n",
    "# [!] 0.5 min\n",
    "with open(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}reviews.csv\") as f:\n",
    "    review_df = pd.read_csv(f, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the reviews\n",
    "# [!] 20 min\n",
    "\n",
    "review_df[\"text\"] = review_df[\"text\"].str.lower() # make text lowercase\n",
    "review_df[\"text\"] = review_df[\"text\"].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new data frame for keywords\n",
    "# [!] 30 min\n",
    "review_keywords_df = review_df[[\"business_id\", \"text\"]].explode(\"text\").rename(columns={\"text\": \"keyword\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with keyword counts\n",
    "# [!] 9 min\n",
    "temp = review_keywords_df.groupby([\"business_id\", \"keyword\"]).size().reset_index(name=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each business id, get the top 10 keywords with the highest count\n",
    "# [!] 20 min\n",
    "top_keywords_per_business = (temp.groupby(\"business_id\")\n",
    "                             .apply(lambda x: x.nlargest(5, \"count\"))\n",
    "                             .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_keywords_per_business.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_keywords = pd.concat([business_keywords_addition, top_keywords_per_business[[\"business_id\", \"keyword\"]]], ignore_index=True)\n",
    "business_keywords.drop_duplicates(inplace=True)\n",
    "business_keywords.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# remove the rows with no keywords\n",
    "business_keywords = business_keywords[business_keywords[\"keyword\"] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the business keywords in a csv file\n",
    "file_name = f\"data/02_postprocessing/{'sample/' if SAMPLE else ''}businesses_keywords.csv\"\n",
    "with open(file_name, \"w\") as f:\n",
    "    business_keywords.to_csv(f, index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load user data\n",
    "file_name = f\"data/01_cleaned/{'sample/' if SAMPLE else ''}users.csv\"\n",
    "with open(file_name, \"r\") as f:\n",
    "    users = pd.read_csv(f, header=0)\n",
    "# Load friend data\n",
    "file_name = f\"data/01_cleaned/{'sample/' if SAMPLE else ''}friends.csv\"\n",
    "with open(file_name, \"r\") as f:\n",
    "    friends = pd.read_csv(f, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f\"data/02_postprocessing/{'sample/' if SAMPLE else ''}users.csv\"\n",
    "with open(file_name, \"w\") as f:\n",
    "    users.to_csv(f, index=False, header=True)\n",
    "file_name = f\"data/02_postprocessing/{'sample/' if SAMPLE else ''}friends.csv\"\n",
    "with open(file_name, \"w\") as f:\n",
    "    friends.to_csv(f, index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
