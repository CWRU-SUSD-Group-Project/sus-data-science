{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import statistics\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "_ = nltk.download(\"stopwords\", quiet=True)\n",
    "_ = nltk.download(\"punkt\", quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data/02_postprocessing direction if it does not exist\n",
    "if not os.path.exists(\"data/02_postprocessing\"):\n",
    "    os.makedirs(\"data/02_postprocessing\")\n",
    "# Create the data/02_postprocessing/sample directory if it does not exist\n",
    "if not os.path.exists(\"data/02_postprocessing/sample\"):\n",
    "    os.makedirs(\"data/02_postprocessing/sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silent_remove(filename):\n",
    "    try:\n",
    "        os.remove(filename)\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed so that it can be run on the sample data or the full data just by switching one variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to True to run the script on the sample data\n",
    "# Set this to False to run the script on the full data (takes much longer)\n",
    "SAMPLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section performs rating normalization (technically standardization) to all ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [!] 4 minutes to load\n",
    "with open(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}ratings.json\") as f:\n",
    "    ratings_original = [json.loads(line) for line in f]\n",
    "with open(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}users.json\") as f:\n",
    "    users_original = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings_dict = {}\n",
    "for rating in ratings_original:\n",
    "    user_id = rating[\"user_id\"]\n",
    "    if user_id not in user_ratings_dict.keys():\n",
    "        user_ratings_dict[user_id] = {\"rating_objs\": [rating], \"ratings\": [(rating[\"rating_id\"], rating[\"stars\"])]}\n",
    "    else:\n",
    "        user_ratings_dict[user_id][\"rating_objs\"].append(rating)\n",
    "        user_ratings_dict[user_id][\"ratings\"].append((rating[\"rating_id\"], rating[\"stars\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to determine the cut off for how many ratings a user should have before we\n",
    "# apply z-score normalization\n",
    "\n",
    "# This outputs the ratio between the number of ratings that would be standardized\n",
    "# and all ratings in the dataset\n",
    "\n",
    "cutoff = 5\n",
    "num_ratings = [len(user[\"ratings\"]) for user in user_ratings_dict.values()]\n",
    "rating_count = Counter(num_ratings)\n",
    "rating_counter_agg = [(tup[0], tup[1], tup[0] * tup[1]) for tup in rating_count.items()]\n",
    "ratio = sum([tup[2] for tup in rating_counter_agg if tup[0] >= cutoff]) / sum([tup[2] for tup in rating_counter_agg])\n",
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_not_standardized = []\n",
    "users_standardized = []\n",
    "for user_id, user_ratings in user_ratings_dict.items():\n",
    "    if (\n",
    "        len(user_ratings[\"ratings\"]) >= cutoff\n",
    "        and len(set(list(zip(*user_ratings[\"ratings\"]))[1])) >= 2\n",
    "    ):\n",
    "        users_standardized.append(user_id)\n",
    "        user_ratings[\"avg_rating\"] = statistics.mean(\n",
    "            list(zip(*user_ratings[\"ratings\"]))[1]\n",
    "        )\n",
    "        user_ratings[\"std_dev\"] = statistics.stdev(\n",
    "            list(zip(*user_ratings[\"ratings\"]))[1]\n",
    "        )\n",
    "        user_ratings[\"standardized_ratings\"] = [\n",
    "            (\n",
    "                rating[0],\n",
    "                (rating[1] - user_ratings[\"avg_rating\"]) / user_ratings[\"std_dev\"],\n",
    "            )\n",
    "            for rating in user_ratings[\"ratings\"]\n",
    "        ]\n",
    "    else:\n",
    "        users_not_standardized.append(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all ratings standardized by user\n",
    "user_standardized_ratings = [\n",
    "    rating\n",
    "    for user_ratings in [\n",
    "        user_rating\n",
    "        for user_rating in user_ratings_dict.values()\n",
    "        if \"standardized_ratings\" in user_rating.keys()\n",
    "    ]\n",
    "    for rating in user_ratings[\"standardized_ratings\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize all other ratings with respect to each other\n",
    "not_standardized_ratings = [\n",
    "    rating\n",
    "    for user_ratings in [\n",
    "        user_ratings_dict[user_id] for user_id in users_not_standardized\n",
    "    ]\n",
    "    for rating in user_ratings[\"ratings\"]\n",
    "]\n",
    "mean = statistics.mean(list(zip(*not_standardized_ratings))[1])\n",
    "std_dev = statistics.stdev(list(zip(*not_standardized_ratings))[1])\n",
    "pool_standardized_ratings = [\n",
    "    (rating[0], (rating[1] - mean) / std_dev) for rating in not_standardized_ratings\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = {rating[\"rating_id\"]: rating for rating in ratings_original}\n",
    "for rating in user_standardized_ratings + pool_standardized_ratings:\n",
    "    ratings[rating[0]][\"standardized_rating\"] = rating[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a min-max normalized standardized rating for each rating object\n",
    "# The attribute will be called \"norm_std_rating\"\n",
    "\n",
    "rating_df = pd.DataFrame(ratings_original).drop(\n",
    "    columns=[\"business_id\", \"rating_id\"]\n",
    ")\n",
    "max_std_rating = rating_df[\"standardized_rating\"].max()\n",
    "min_std_rating = rating_df[\"standardized_rating\"].min()\n",
    "\n",
    "rating_df[\"norm_std_rating\"] = (\n",
    "    (rating_df[\"standardized_rating\"] - min_std_rating) /\n",
    "    (max_std_rating - min_std_rating)\n",
    ")\n",
    "rating_df[\"norm_std_rating\"] = (rating_df[\"norm_std_rating\"] * 4) + 1\n",
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make standardized_rating vs norm_std_rating a yes-no attribute\n",
    "# Make it wide-form data\n",
    "rating_df_wide_list = []\n",
    "for index, row in rating_df.iterrows():\n",
    "    rating_df_wide_list.append({\n",
    "        \"user_id\": row[\"user_id\"],\n",
    "        \"standardized\": \"Yes\",\n",
    "        \"rating\": row[\"norm_std_rating\"],\n",
    "    })\n",
    "    rating_df_wide_list.append({\n",
    "        \"user_id\": row[\"user_id\"],\n",
    "        \"standardized\": \"No\",\n",
    "        \"rating\": row[\"stars\"],\n",
    "    })\n",
    "rating_df_wide = pd.DataFrame(rating_df_wide_list)\n",
    "rating_df_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the user with the max average rating and the user with the min average rating\n",
    "\n",
    "graphing_cutoff = 20\n",
    "graph_pool = [\n",
    "    user\n",
    "    for user in users_standardized\n",
    "    if len(user_ratings_dict[user][\"ratings\"]) >= graphing_cutoff\n",
    "]\n",
    "print(f\"Narrowed down to {len(graph_pool) * 100 / len(users_standardized)}%\")\n",
    "\n",
    "max_avg_user = max(users_standardized, key=lambda x: user_ratings_dict[x][\"avg_rating\"])\n",
    "min_avg_user = min(users_standardized, key=lambda x: user_ratings_dict[x][\"avg_rating\"])\n",
    "max_std_dev_user = max(\n",
    "    users_standardized, key=lambda x: user_ratings_dict[x][\"std_dev\"]\n",
    ")\n",
    "min_std_dev_user = min(\n",
    "    list(set(users_standardized) - set([max_avg_user])), key=lambda x: user_ratings_dict[x][\"std_dev\"]\n",
    ")\n",
    "print(f\"Found 4 users: {max_avg_user}, {min_avg_user}, {max_std_dev_user}, {min_std_dev_user}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_df = rating_df_wide.copy()\n",
    "graph_df[\"user_id\"] = graph_df[\"user_id\"].map({\n",
    "    max_avg_user: \"max_avg\",\n",
    "    min_avg_user: \"min_avg\",\n",
    "    max_std_dev_user: \"max_std_dev\",\n",
    "    min_std_dev_user: \"min_std_dev\",\n",
    "}).fillna(\"other\")\n",
    "graph_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.displot(\n",
    "    data=graph_df.loc[graph_df[\"user_id\"] != \"other\"],\n",
    "    kind=\"hist\",\n",
    "    x=\"rating\",\n",
    "    hue=\"standardized\",\n",
    "    col=\"user_id\",\n",
    "    col_order=[\"max_avg\", \"min_avg\", \"max_std_dev\", \"min_std_dev\"],\n",
    "    col_wrap=2,\n",
    "    stat=\"probability\",\n",
    "    common_norm=False,\n",
    "    bins=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.displot(\n",
    "    data=graph_df,\n",
    "    kind=\"hist\",\n",
    "    x=\"rating\",\n",
    "    hue=\"standardized\",\n",
    "    stat=\"probability\",\n",
    "    bins=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f\"data/02_postprocessing/{'sample/' if SAMPLE else ''}ratings.csv\"\n",
    "silent_remove(file_name)\n",
    "with open(file_name, \"w\") as f:\n",
    "    rating_df.to_csv(f, index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Businesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories >> Type, Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}businesses.json\") as f:\n",
    "    businesses = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count most frequently category occurrences in businesses.json\n",
    "category_counts = {}\n",
    "for business in businesses:\n",
    "    categories_str = business.get(\"categories\", '')\n",
    "    if categories_str:\n",
    "        categories = categories_str.split(', ')\n",
    "        for category in categories:\n",
    "            category_counts[category] = category_counts.get(category, 0) + 1\n",
    "\n",
    "# Find the most frequent categories\n",
    "category_counts = sorted(category_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "category_counts[:5]\n",
    "\n",
    "# Create a list of the most frequent categories\n",
    "top_categories = [category[0] for category in category_counts[:5]]\n",
    "\n",
    "# print the top 5 most frequent categories\n",
    "top_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the businesses that have at least one of the top 5 categories using a dictionary and create a new attribute \"type\" for each business that states which of the top 5 categories it belongs to\n",
    "businesses_dict = {}\n",
    "for business in businesses:\n",
    "    categories_str = business.get(\"categories\", '')\n",
    "    if categories_str:\n",
    "        categories = categories_str.split(', ')\n",
    "        for category in categories:\n",
    "            if category in top_categories:\n",
    "                business[\"type\"] = category\n",
    "                businesses_dict[business[\"business_id\"]] = business\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silent_remove(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}businesses.json\")\n",
    "with open(f\"data/01_cleaned/{'sample' if SAMPLE else ''}/businesses.json\", \"a\") as f:\n",
    "    for business in businesses_dict.values():\n",
    "        f.write(json.dumps(business) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read business JSON file\n",
    "with open(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}businesses.json\") as f:\n",
    "    businesses = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "custom_stop_words = [\",\", \"&\", \"-\", \"(\", \")\", \".\", \"'\", \"!\", \"?\", \":\", \";\", \"[\", \"]\", \"/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract keywords from each business entry for category and name attributes using dictionary\n",
    "business_keywords = {}\n",
    "for business in businesses:\n",
    "    business_keywords[business[\"business_id\"]] = {}\n",
    "    business_keywords[business[\"business_id\"]][\"category\"] = []\n",
    "    business_keywords[business[\"business_id\"]][\"name\"] = []\n",
    "    for word in word_tokenize(business[\"categories\"]):\n",
    "        if word not in stop_words and word not in custom_stop_words:\n",
    "            business_keywords[business[\"business_id\"]][\"category\"].append(word)\n",
    "    for word in word_tokenize(business[\"name\"]):\n",
    "        if word not in stop_words and word not in custom_stop_words:\n",
    "            business_keywords[business[\"business_id\"]][\"name\"].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read review JSON file\n",
    "with open(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}reviews.json\") as f:\n",
    "    reviews = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract keywords from each review entry for text attribute using dictionary\n",
    "review_keywords = {}\n",
    "for review in reviews:\n",
    "    review_keywords[review[\"review_id\"]] = []\n",
    "    for word in word_tokenize(review[\"text\"]):\n",
    "        if word not in stop_words and word not in custom_stop_words:\n",
    "            review_keywords[review[\"review_id\"]].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of business_id to a list of review_ids\n",
    "business_review_dict = {}\n",
    "for review in reviews:\n",
    "    if review[\"business_id\"] not in business_review_dict.keys():\n",
    "        business_review_dict[review[\"business_id\"]] = [review[\"review_id\"]]\n",
    "    else:\n",
    "        business_review_dict[review[\"business_id\"]].append(review[\"review_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine keywords from all reviews, category, and name for each business\n",
    "# some businesses do not have any reviews, so we only combine category and name keywords for those businesses using dictionary\n",
    "business_keywords_combined = {}\n",
    "for business in businesses:\n",
    "    business_keywords_combined[business[\"business_id\"]] = []\n",
    "    if business[\"business_id\"] in business_review_dict.keys():\n",
    "        for review_id in business_review_dict[business[\"business_id\"]]:\n",
    "            business_keywords_combined[business[\"business_id\"]] += review_keywords[review_id]\n",
    "    business_keywords_combined[business[\"business_id\"]] += business_keywords[business[\"business_id\"]][\"category\"]\n",
    "    business_keywords_combined[business[\"business_id\"]] += business_keywords[business[\"business_id\"]][\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the keywords for each business with their name\n",
    "for business in businesses:\n",
    "    print(business[\"name\"] + \": \")\n",
    "    print(business_keywords_combined[business[\"business_id\"]])\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
