{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "_ = nltk.download(\"stopwords\", quiet=True)\n",
    "_ = nltk.download(\"punkt\", quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data/02_postprocessing direction if it does not exist\n",
    "if not os.path.exists(\"data/02_postprocessing\"):\n",
    "    os.makedirs(\"data/02_postprocessing\")\n",
    "# Create the data/02_postprocessing/sample directory if it does not exist\n",
    "if not os.path.exists(\"data/02_postprocessing/sample\"):\n",
    "    os.makedirs(\"data/02_postprocessing/sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silent_remove(filename):\n",
    "    try:\n",
    "        os.remove(filename)\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed so that it can be run on the sample data or the full data just by switching one variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to True to run the script on the sample data\n",
    "# Set this to False to run the script on the full data (takes much longer)\n",
    "SAMPLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section performs rating normalization (technically standardization) to all ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ratings and users data\n",
    "file_name = f\"data/01_cleaned/{'sample/' if SAMPLE else ''}ratings.csv\"\n",
    "ratings = pd.read_csv(file_name, header=0)\n",
    "file_name = f\"data/01_cleaned/{'sample/' if SAMPLE else ''}users.csv\"\n",
    "users = pd.read_csv(file_name, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index on the \"user_id\" and \"rating_id\" columns\n",
    "ratings = ratings.set_index([\"user_id\", \"rating_id\"])\n",
    "# Index on the \"user_id\" column for the users data\n",
    "users = users.set_index(\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of ratings for each user_id in the ratings data frame\n",
    "user_ratings = ratings.groupby(\"user_id\").agg(\n",
    "    num_ratings = pd.NamedAgg(column=\"stars\", aggfunc=\"count\"),\n",
    "    mean_rating = pd.NamedAgg(column=\"stars\", aggfunc=\"mean\"),\n",
    "    std_rating = pd.NamedAgg(column=\"stars\", aggfunc=\"std\"),\n",
    ")\n",
    "user_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a \"num_ratings\" to the users data frame by joining the users and user_ratings data frames\n",
    "users = users.join(user_ratings, on=\"user_id\", how=\"left\")\n",
    "# Set null values to 0\n",
    "users[\"num_ratings\"].fillna(0, inplace=True)\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a \"above_cutoff\" column to the users data frame\n",
    "# This column is True if the user has more than \"cutoff\" ratings in the ratings data frame\n",
    "cutoff = 5 # TODO justify this\n",
    "users[\"above_cutoff\"] = users[\"num_ratings\"] > cutoff\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings[\"std_rating\"] = np.NaN\n",
    "cutoff_users = users[users[\"above_cutoff\"]]\n",
    "ratings.loc[cutoff_users.index, \"std_rating\"] = (\n",
    "    ratings.loc[cutoff_users.index, \"stars\"] - cutoff_users[\"mean_rating\"]\n",
    ") / cutoff_users[\"std_rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.loc[cutoff_users.index].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_users = users[~users[\"above_cutoff\"]]\n",
    "other_mean = ratings.loc[other_users.index, \"stars\"].mean()\n",
    "other_std = ratings.loc[other_users.index, \"stars\"].std()\n",
    "ratings.loc[other_users.index, \"std_rating\"] = (\n",
    "    ratings.loc[other_users.index, \"stars\"] - other_mean\n",
    ") / other_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.loc[other_users.index].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_std = ratings[\"std_rating\"].min()\n",
    "max_std = ratings[\"std_rating\"].max()\n",
    "ratings[\"norm_std_rating\"] = (((ratings[\"std_rating\"] - min_std) / (max_std - min_std)) * 4) + 1\n",
    "ratings.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reindexed_ratings = ratings.reset_index()\n",
    "reindexed_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f\"data/02_postprocessing/{'sample/' if SAMPLE else ''}ratings.csv\"\n",
    "with open(file_name, \"w\") as f:\n",
    "    reindexed_ratings.to_csv(f, index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Businesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories >> Type, Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}businesses.csv\") as f:\n",
    "    businesses = pd.read_csv(f, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define category grouping based on similarity\n",
    "category_groups = {\n",
    "    'Restaurants': ['Restaurants','Food', 'Breakfast & Brunch', 'Fast Food', 'Burgers', 'Pizza', 'Sandwiches', 'American (Traditional)', 'American (New)', 'Mexican', 'Chicken Wings', 'Salad', 'Chinese', 'Cafes', 'Sushi Bars', 'Barbeque', 'Southern', 'Japanese', 'Steakhouses', 'Juice Bars & Smoothies', 'Asian Fusion', 'Diners', 'Tex-Mex', 'Thai', 'Mediterranean', 'Indian', 'Vietnamese', 'Cajun/Creole', 'Latin American', 'Cuban', 'Puerto Rican', 'Caribbean', 'Japanese', 'Spanish', 'Korean', 'French', 'Halal', 'Mongolian', 'Canadian (New)', 'Filipino', 'Greek', 'Brazilian', 'Argentine', 'Hawaiian', 'Afghan', 'Indonesian', 'German', 'Ramen', 'Poke', 'Hot Pot', 'German', 'Pakistani', 'Uzbek', 'Persian/Iranian', 'Russian', 'Burmese', 'New Mexican Cuisine'],\n",
    "    'Shopping': ['Shopping', 'Fashion', 'Specialty Food', 'Bakeries', 'Grocery', 'Flowers & Gifts', 'Furniture Stores', 'Jewelry', 'Shoe Stores', 'Accessories', 'Vintage & Consignment', 'Sporting Goods', 'Beer, Wine & Spirits', 'Department Stores', 'Bookstores', 'Electronics', 'Drugstores', 'Music & DVDs', 'Toy Stores', 'Tattoo', 'Eyewear & Opticians', 'Optometrists', 'Comic Books', 'Antiques', 'Gift Shops', 'Mobile Phones', 'Discount Store', 'Hardware Stores', 'Pet Stores', 'Appliances & Repair', 'Appliances', 'Vape Shops', 'Outlet Stores', 'Home & Garden', 'Building Supplies', 'Art Supplies', 'Thrift Stores', 'Hobby Shops', 'Musical Instruments & Teachers', 'Mattresses', 'Bike Repair/Maintenance', 'Books, Mags, Music & Video', 'Computers', 'Mobile Phone Accessories', 'Cosmetics & Beauty Supply', 'Eyelash Service', 'Hair Extensions', 'Hair Stylists', 'Waxing', 'Cosmetic Surgeons', 'Makeup Artists', 'Hair Loss Centers', 'Medical Spas', 'Nail Technicians', 'Hair Salons', 'Nail Salons', 'Massage', 'Day Spas', 'Barbers', 'Massage Therapy', 'Tattoo Removal', 'Piercing', 'Laser Hair Removal', 'Eyebrow Services', 'Permanent Makeup', 'Acne Treatment', 'Weight Loss Centers', 'Medical Supplies', 'Optometrists', 'Health Markets', 'Nutritionists', 'Physical Therapy', 'Dermatologists', 'Chiropractors', 'Hospitals', 'Acupuncture', 'Cryotherapy', 'Medical Centers', 'Sports Medicine', 'Alternative Medicine', 'Prenatal/Perinatal Care', 'Ophthalmologists', 'Internal Medicine', 'Allergists', 'Audiologist', 'Ear Nose & Throat', 'Allergists'],\n",
    "    'Home Services': ['Home Services', 'Local Services', 'Real Estate', 'Contractors', 'Apartments', 'Home Decor', 'Movers', 'Mattresses', 'Appliances & Repair', 'Appliances', 'Home & Garden', 'Building Supplies', 'Security Systems', 'Waterproofing', 'Insulation Installation', 'Pest Control', 'Heating & Air Conditioning/HVAC', 'Plumbing', 'Carpet Cleaning', 'Air Duct Cleaning', 'Home Inspectors', 'Electricians', 'Solar Installation', 'Solar Panel Cleaning', 'Windows Installation', 'Glass & Mirrors', 'Window Washing', 'Pressure Washers', 'Roofing', 'Gutter Services', 'Siding', 'Carpenters', 'Masonry/Concrete', 'Fireplace Services', 'Carpeting', 'Home Automation', 'Handyman', 'Painters', 'Landscape Architects', 'Irrigation', 'Fences & Gates', 'Pool & Hot Tub Service', 'Pool Cleaners', 'Tree Services', 'Septic Services', 'Water Purification Services', 'Oil Change Stations', 'Excavation Services', 'Snow Removal'],\n",
    "    'Beauty & Spas': [ 'Beauty & Spas', 'Hair Salons', 'Nail Salons', 'Hair Removal', 'Skin Care', 'Day Spas', 'Barbers', 'Massage', 'Waxing', 'Massage Therapy', 'Tattoo Removal', 'Piercing', 'Laser Hair Removal', 'Eyebrow Services', 'Permanent Makeup', 'Acne Treatment', 'Weight Loss Centers', 'Health Markets', 'Nutritionists', 'Physical Therapy', 'Dermatologists', 'Chiropractors', 'Medical Spas', 'Cosmetic Surgeons', 'Makeup Artists', 'Hair Loss Centers', 'Medical Supplies', 'Optometrists', 'Alternative Medicine', 'Prenatal/Perinatal Care', 'Ophthalmologists', 'Internal Medicine', 'Allergists', 'Audiologist', 'Ear Nose & Throat', 'Allergists'],\n",
    "    'Nightlife': ['Nightlife', 'Bars', 'Sports Bars', 'Pubs', 'Cocktail Bars', 'Beer Gardens', 'Wine Bars', 'Karaoke', 'Breweries', 'Dive Bars', 'Wine Tasting Room', 'Jazz & Blues', 'Tiki Bars', 'Bartenders', 'Distilleries'],\n",
    "    'Other': []\n",
    "}\n",
    "# Make the lists into sets\n",
    "for key in category_groups.keys():\n",
    "    category_groups[key] = set([category.lower() for category in category_groups[key]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make category a list\n",
    "businesses[\"categories\"] = businesses[\"categories\"].apply(lambda x: x.split(\", \") if type(x) == str else [])\n",
    "# Make category lowercase\n",
    "businesses[\"categories\"] = businesses[\"categories\"].apply(lambda x: set([category.lower() for category in x]))\n",
    "# Map according to the category_groups mapping\n",
    "businesses[\"categories\"] = businesses[\"categories\"].apply(lambda x: [cat_name for cat_name, cat_values in category_groups.items() if len(cat_values.intersection(x)) > 0])\n",
    "# Pick the top category according to the following order of preference: Restaurants > Shopping > Home Services > Beauty & Spas > Nightlife > Other\n",
    "def category_sort(category) -> int:\n",
    "    return [\"Restaurants\", \"Shopping\", \"Home Services\", \"Beauty & Spas\", \"Nightlife\", \"Other\"].index(category)\n",
    "businesses[\"categories\"] = businesses[\"categories\"].apply(\n",
    "    lambda x: sorted(list(x), key=category_sort)[0] if len(x) > 0 else \"Other\")\n",
    "# Rename category to type\n",
    "businesses.rename(columns={\"categories\": \"type\"}, inplace=True)\n",
    "businesses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f\"data/02_postprocessing/{'sample/' if SAMPLE else ''}businesses.csv\"\n",
    "with open(file_name, \"w\") as f:\n",
    "    businesses.to_csv(f, index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read business csv file\n",
    "with open(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}businesses.csv\") as f:\n",
    "    business_df = pd.read_csv(f, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "custom_stop_words = [\",\", \"&\", \"-\", \"(\", \")\", \".\", \"'\", \"!\", \"?\", \":\", \";\", \"[\", \"]\", \"/\", \"I\", \"'ve\", \"'s\", \"n't\", \"a\", \"``\", \"also\", \"'ll\", \"$\", \"'d\", \" \"]\n",
    "# add numbers to the custom_stop_words list 1 to 100\n",
    "custom_stop_words.extend([str(i) for i in range(100)])\n",
    "# combine the stop_words and custom_stop_words lists and make it into a set\n",
    "all_stop_words = set(stopwords.words(\"english\") + custom_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract keywords from each business entry for category and name attributes using dictionary; make lowercase\n",
    "business_df[\"categories\"] = business_df[\"categories\"].str.lower()\n",
    "business_df[\"name\"] = business_df[\"name\"].str.lower()\n",
    "\n",
    "# make a new data frame for keywords from categories and name attributes\n",
    "# split the categories string into a list of words and remove stop words\n",
    "# if categories is None don't run\n",
    "if business_df[\"categories\"].isnull().values.any() == False:\n",
    "    business_df[\"categories\"] = business_df[\"categories\"].apply(lambda x: [word for word in re.split(\"\\W+\", x) if word not in all_stop_words])\n",
    "business_df[\"name\"] = business_df[\"name\"].apply(lambda x: [word for word in re.split(\"\\W+\", x) if word not in all_stop_words])\n",
    "business_keywords_df = business_df[[\"business_id\", \"name\", \"categories\"]].reset_index(drop=True)\n",
    "# combine the name and categories lists into a keywords list\n",
    "business_keywords_df[\"keywords\"] = business_keywords_df[\"name\"].astype(str) + business_keywords_df[\"categories\"].astype(str)\n",
    "# remove the name and categories columns\n",
    "business_keywords_df = business_keywords_df.drop(columns=[\"name\", \"categories\"])\n",
    "# explode the keywords list\n",
    "business_keywords_addition = business_keywords_df.explode(\"keywords\").reset_index(drop=True)\n",
    "# rename the column\n",
    "business_keywords_addition.rename(columns={\"keywords\": \"keyword\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read review JSON file\n",
    "with open(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}reviews.csv\") as f:\n",
    "    review_df = pd.read_csv(f, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the stop_words and custom_stop_words lists and make it into a set\n",
    "all_stop_words = set(stopwords.words(\"english\") + custom_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df[\"text\"] = review_df[\"text\"].str.lower() # make text lowercase\n",
    "# Make the text column a list by tokenizing it\n",
    "def tokenize(text):\n",
    "    if text is None:\n",
    "        return []\n",
    "    return [word for word in re.split('\\W+', text) if word not in all_stop_words]\n",
    "review_df[\"text\"] = review_df[\"text\"].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new data frame for keywords\n",
    "review_keywords_df = review_df[[\"business_id\", \"text\"]].explode(\"text\").rename(columns={\"text\": \"keyword\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with keyword counts\n",
    "temp = review_keywords_df.groupby([\"business_id\", \"keyword\"]).size().reset_index(name=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each business id, get the top 10 keywords with the highest count\n",
    "top_keywords_per_business = (temp.groupby(\"business_id\")\n",
    "                             .apply(lambda x: x.nlargest(5, \"count\"))\n",
    "                             .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_keywords_per_business.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_keywords = pd.concat([business_keywords_addition, top_keywords_per_business[[\"business_id\", \"keyword\"]]], ignore_index=True)\n",
    "business_keywords.drop_duplicates(inplace=True)\n",
    "business_keywords.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# remove the rows with no keywords\n",
    "business_keywords = business_keywords[business_keywords[\"keyword\"] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the business keywords in a csv file\n",
    "file_name = f\"data/02_postprocessing/{'sample/' if SAMPLE else ''}businesses_keywords.csv\"\n",
    "with open(file_name, \"w\") as f:\n",
    "    business_keywords.to_csv(f, index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
