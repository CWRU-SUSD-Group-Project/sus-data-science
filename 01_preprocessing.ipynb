{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "_ = nltk.download(\"stopwords\", quiet=True)\n",
    "_ = nltk.download(\"punkt\", quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data/02_postprocessing direction if it does not exist\n",
    "if not os.path.exists(\"data/02_postprocessing\"):\n",
    "    os.makedirs(\"data/02_postprocessing\")\n",
    "# Create the data/02_postprocessing/sample directory if it does not exist\n",
    "if not os.path.exists(\"data/02_postprocessing/sample\"):\n",
    "    os.makedirs(\"data/02_postprocessing/sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silent_remove(filename):\n",
    "    try:\n",
    "        os.remove(filename)\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed so that it can be run on the sample data or the full data just by switching one variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to True to run the script on the sample data\n",
    "# Set this to False to run the script on the full data (takes much longer)\n",
    "SAMPLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section performs rating normalization (technically standardization) to all ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ratings and users data\n",
    "file_name = f\"data/01_cleaned/{'sample/' if SAMPLE else ''}ratings.csv\"\n",
    "ratings = pd.read_csv(file_name, header=0)\n",
    "file_name = f\"data/01_cleaned/{'sample/' if SAMPLE else ''}users.csv\"\n",
    "users = pd.read_csv(file_name, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index on the \"user_id\" and \"rating_id\" columns\n",
    "ratings = ratings.set_index([\"user_id\", \"rating_id\"])\n",
    "# Index on the \"user_id\" column for the users data\n",
    "users = users.set_index(\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of ratings for each user_id in the ratings data frame\n",
    "user_ratings = ratings.groupby(\"user_id\").agg(\n",
    "    num_ratings = pd.NamedAgg(column=\"stars\", aggfunc=\"count\"),\n",
    "    mean_rating = pd.NamedAgg(column=\"stars\", aggfunc=\"mean\"),\n",
    "    std_rating = pd.NamedAgg(column=\"stars\", aggfunc=\"std\"),\n",
    ")\n",
    "user_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a \"num_ratings\" to the users data frame by joining the users and user_ratings data frames\n",
    "users = users.join(user_ratings, on=\"user_id\", how=\"left\")\n",
    "# Set null values to 0\n",
    "users[\"num_ratings\"].fillna(0, inplace=True)\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a \"above_cutoff\" column to the users data frame\n",
    "# This column is True if the user has more than \"cutoff\" ratings in the ratings data frame\n",
    "cutoff = 5 # TODO justify this\n",
    "users[\"above_cutoff\"] = users[\"num_ratings\"] > cutoff\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings[\"std_rating\"] = np.NaN\n",
    "cutoff_users = users[users[\"above_cutoff\"]]\n",
    "ratings.loc[cutoff_users.index, \"std_rating\"] = (\n",
    "    ratings.loc[cutoff_users.index, \"stars\"] - cutoff_users[\"mean_rating\"]\n",
    ") / cutoff_users[\"std_rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.loc[cutoff_users.index].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_users = users[~users[\"above_cutoff\"]]\n",
    "other_mean = ratings.loc[other_users.index, \"stars\"].mean()\n",
    "other_std = ratings.loc[other_users.index, \"stars\"].std()\n",
    "ratings.loc[other_users.index, \"std_rating\"] = (\n",
    "    ratings.loc[other_users.index, \"stars\"] - other_mean\n",
    ") / other_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.loc[other_users.index].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_std = ratings[\"std_rating\"].min()\n",
    "max_std = ratings[\"std_rating\"].max()\n",
    "ratings[\"norm_std_rating\"] = (((ratings[\"std_rating\"] - min_std) / (max_std - min_std)) * 4) + 1\n",
    "ratings.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reindexed_ratings = ratings.reset_index()\n",
    "reindexed_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f\"data/02_postprocessing/{'sample/' if SAMPLE else ''}ratings.csv\"\n",
    "with open(file_name, \"w\") as f:\n",
    "    reindexed_ratings.to_csv(f, index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Businesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories >> Type, Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}businesses.json\") as f:\n",
    "    businesses = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count most frequently category occurrences in businesses.json\n",
    "category_counts = {}\n",
    "for business in businesses:\n",
    "    categories_str = business.get(\"categories\", '')\n",
    "    if categories_str:\n",
    "        categories = categories_str.split(', ')\n",
    "        for category in categories:\n",
    "            category_counts[category] = category_counts.get(category, 0) + 1\n",
    "\n",
    "# Find the most frequent categories\n",
    "category_counts = sorted(category_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "category_counts[:1000]\n",
    "\n",
    "# Create a list of the most frequent categories\n",
    "top_categories = [category[0] for category in category_counts[:1000]]\n",
    "\n",
    "# print the top 500 most frequent categories\n",
    "print(top_categories)\n",
    "\n",
    "# Keep only the businesses that have at least one of the top 5 categories using a dictionary and create a new attribute \"type\" for each business that states which of the top 5 categories it belongs to\n",
    "businesses_dict = {}\n",
    "for business in businesses:\n",
    "    categories_str = business.get(\"categories\", '')\n",
    "    if categories_str:\n",
    "        categories = categories_str.split(', ')\n",
    "        for category in categories:\n",
    "            if category in top_categories:\n",
    "                business[\"type\"] = category\n",
    "                businesses_dict[business[\"business_id\"]] = business\n",
    "                break\n",
    "        else:\n",
    "            # If no matching category is found, assign the business to the \"Other\" category\n",
    "            business[\"type\"] = \"Other\"\n",
    "            businesses_dict[business[\"business_id\"]] = business\n",
    "\n",
    "# Define category grouping based on similarity\n",
    "category_groups = {\n",
    "    'Restaurants': ['Restaurants','Food', 'Breakfast & Brunch', 'Fast Food', 'Burgers', 'Pizza', 'Sandwiches', 'American (Traditional)', 'American (New)', 'Mexican', 'Chicken Wings', 'Salad', 'Chinese', 'Cafes', 'Sushi Bars', 'Barbeque', 'Southern', 'Japanese', 'Steakhouses', 'Juice Bars & Smoothies', 'Asian Fusion', 'Diners', 'Tex-Mex', 'Thai', 'Mediterranean', 'Indian', 'Vietnamese', 'Cajun/Creole', 'Latin American', 'Cuban', 'Puerto Rican', 'Caribbean', 'Japanese', 'Spanish', 'Korean', 'French', 'Halal', 'Mongolian', 'Canadian (New)', 'Filipino', 'Greek', 'Brazilian', 'Argentine', 'Hawaiian', 'Afghan', 'Indonesian', 'German', 'Ramen', 'Poke', 'Hot Pot', 'German', 'Pakistani', 'Uzbek', 'Persian/Iranian', 'Russian', 'Burmese', 'New Mexican Cuisine'],\n",
    "    'Shopping': ['Shopping', 'Fashion', 'Specialty Food', 'Bakeries', 'Grocery', 'Flowers & Gifts', 'Furniture Stores', 'Jewelry', 'Shoe Stores', 'Accessories', 'Vintage & Consignment', 'Sporting Goods', 'Beer, Wine & Spirits', 'Department Stores', 'Bookstores', 'Electronics', 'Drugstores', 'Music & DVDs', 'Toy Stores', 'Tattoo', 'Eyewear & Opticians', 'Optometrists', 'Comic Books', 'Antiques', 'Gift Shops', 'Mobile Phones', 'Discount Store', 'Hardware Stores', 'Pet Stores', 'Appliances & Repair', 'Appliances', 'Vape Shops', 'Outlet Stores', 'Home & Garden', 'Building Supplies', 'Art Supplies', 'Thrift Stores', 'Hobby Shops', 'Musical Instruments & Teachers', 'Mattresses', 'Bike Repair/Maintenance', 'Books, Mags, Music & Video', 'Computers', 'Mobile Phone Accessories', 'Cosmetics & Beauty Supply', 'Eyelash Service', 'Hair Extensions', 'Hair Stylists', 'Waxing', 'Cosmetic Surgeons', 'Makeup Artists', 'Hair Loss Centers', 'Medical Spas', 'Nail Technicians', 'Hair Salons', 'Nail Salons', 'Massage', 'Day Spas', 'Barbers', 'Massage Therapy', 'Tattoo Removal', 'Piercing', 'Laser Hair Removal', 'Eyebrow Services', 'Permanent Makeup', 'Acne Treatment', 'Weight Loss Centers', 'Medical Supplies', 'Optometrists', 'Health Markets', 'Nutritionists', 'Physical Therapy', 'Dermatologists', 'Chiropractors', 'Hospitals', 'Acupuncture', 'Cryotherapy', 'Medical Centers', 'Sports Medicine', 'Alternative Medicine', 'Prenatal/Perinatal Care', 'Ophthalmologists', 'Internal Medicine', 'Allergists', 'Audiologist', 'Ear Nose & Throat', 'Allergists'],\n",
    "    'Home Services': ['Home Services', 'Local Services', 'Real Estate', 'Contractors', 'Apartments', 'Home Decor', 'Movers', 'Mattresses', 'Appliances & Repair', 'Appliances', 'Home & Garden', 'Building Supplies', 'Security Systems', 'Waterproofing', 'Insulation Installation', 'Pest Control', 'Heating & Air Conditioning/HVAC', 'Plumbing', 'Carpet Cleaning', 'Air Duct Cleaning', 'Home Inspectors', 'Electricians', 'Solar Installation', 'Solar Panel Cleaning', 'Windows Installation', 'Glass & Mirrors', 'Window Washing', 'Pressure Washers', 'Roofing', 'Gutter Services', 'Siding', 'Carpenters', 'Masonry/Concrete', 'Fireplace Services', 'Carpeting', 'Home Automation', 'Handyman', 'Painters', 'Landscape Architects', 'Irrigation', 'Fences & Gates', 'Pool & Hot Tub Service', 'Pool Cleaners', 'Tree Services', 'Septic Services', 'Water Purification Services', 'Oil Change Stations', 'Excavation Services', 'Snow Removal'],\n",
    "    'Beauty & Spas': [ 'Beauty & Spas', 'Hair Salons', 'Nail Salons', 'Hair Removal', 'Skin Care', 'Day Spas', 'Barbers', 'Massage', 'Waxing', 'Massage Therapy', 'Tattoo Removal', 'Piercing', 'Laser Hair Removal', 'Eyebrow Services', 'Permanent Makeup', 'Acne Treatment', 'Weight Loss Centers', 'Health Markets', 'Nutritionists', 'Physical Therapy', 'Dermatologists', 'Chiropractors', 'Medical Spas', 'Cosmetic Surgeons', 'Makeup Artists', 'Hair Loss Centers', 'Medical Supplies', 'Optometrists', 'Alternative Medicine', 'Prenatal/Perinatal Care', 'Ophthalmologists', 'Internal Medicine', 'Allergists', 'Audiologist', 'Ear Nose & Throat', 'Allergists'],\n",
    "    'Nightlife': ['Nightlife', 'Bars', 'Sports Bars', 'Pubs', 'Cocktail Bars', 'Beer Gardens', 'Wine Bars', 'Karaoke', 'Breweries', 'Dive Bars', 'Wine Tasting Room', 'Jazz & Blues', 'Tiki Bars', 'Bartenders', 'Distilleries'],\n",
    "    'Other': []\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize grouped category counts\n",
    "grouped_category_counts = {}\n",
    "\n",
    "# Iterate through businesses and update the grouped categories\n",
    "for business in businesses:\n",
    "    categories_str = business.get(\"categories\", '')\n",
    "    if categories_str:\n",
    "        categories = categories_str.split(', ')\n",
    "        for category in categories:\n",
    "            for group, group_categories in category_groups.items():\n",
    "                if category in group_categories:\n",
    "                        grouped_category_counts[group] = grouped_category_counts.get(group, 0) + 1\n",
    "                        business[\"type\"] = group\n",
    "                        businesses_dict[business[\"business_id\"]] = business\n",
    "                        break\n",
    "            else:\n",
    "                # If no matching category is found, assign the business to the \"Other\" category\n",
    "                grouped_category_counts[\"Other\"] = grouped_category_counts.get(\"Other\", 0) + 1\n",
    "                business[\"type\"] = \"Other\"\n",
    "                businesses_dict[business[\"business_id\"]] = business\n",
    "                        \n",
    "\n",
    "# Find the most frequent grouped categories\n",
    "grouped_category_counts = sorted(grouped_category_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "grouped_category_counts[:6]\n",
    "\n",
    "# Create a list of the most frequent grouped categories\n",
    "top_grouped_categories = [category[0] for category in grouped_category_counts[:6]]\n",
    "\n",
    "# print the top 5 most frequent grouped categories and their counts\n",
    "print(grouped_category_counts[:6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.pie([category[1] for category in category_counts])\n",
    "plt.title(\"Original Categories\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data for the pie chart\n",
    "labels = top_grouped_categories\n",
    "sizes = [count[1] for count in grouped_category_counts[:6]]\n",
    "\n",
    "# Create a pie chart\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140)\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that the pie is drawn as a circle.\n",
    "plt.title('Grouped Categories Distribution')\n",
    "\n",
    "# Show the pie chart\n",
    "plt.show()\n",
    "\n",
    "# print out the grouped categories and their counts \n",
    "grouped_category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the data to save for query processing\n",
    "\n",
    "# Remove the \"categories\" key from test business in business_dict\n",
    "for business in businesses_dict.values():\n",
    "    business.pop(\"categories\", None)\n",
    "    \n",
    "# Make it into a data frame\n",
    "business_df = pd.DataFrame(businesses_dict.values())\n",
    "business_df[\"type\"] = business_df[\"type\"].str.lower() # Make type lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f\"data/02_postprocessing/{'sample/' if SAMPLE else ''}businesses.csv\"\n",
    "with open(file_name, \"w\") as f:\n",
    "    business_df.to_csv(f, index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read business JSON file\n",
    "with open(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}businesses.json\") as f:\n",
    "    businesses = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "custom_stop_words = [\",\", \"&\", \"-\", \"(\", \")\", \".\", \"'\", \"!\", \"?\", \":\", \";\", \"[\", \"]\", \"/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract keywords from each business entry for category and name attributes using dictionary\n",
    "business_keywords = {}\n",
    "for business in businesses:\n",
    "    business_keywords[business[\"business_id\"]] = {\"category\": [], \"name\": []}\n",
    "    for word in word_tokenize(business[\"categories\"]):\n",
    "        if word not in stop_words and word not in custom_stop_words:\n",
    "            business_keywords[business[\"business_id\"]][\"category\"].append(word)\n",
    "    for word in word_tokenize(business[\"name\"]):\n",
    "        if word not in stop_words and word not in custom_stop_words:\n",
    "            business_keywords[business[\"business_id\"]][\"name\"].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read review JSON file\n",
    "with open(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}reviews.json\") as f:\n",
    "    reviews = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract keywords from each review entry for text attribute using dictionary\n",
    "review_keywords = {}\n",
    "for review in reviews:\n",
    "    review_keywords[review[\"review_id\"]] = []\n",
    "    for word in word_tokenize(review[\"text\"]):\n",
    "        if word not in stop_words and word not in custom_stop_words:\n",
    "            review_keywords[review[\"review_id\"]].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of business_id to a list of review_ids\n",
    "business_review_dict = {}\n",
    "for review in reviews:\n",
    "    if review[\"business_id\"] not in business_review_dict.keys():\n",
    "        business_review_dict[review[\"business_id\"]] = [review[\"review_id\"]]\n",
    "    else:\n",
    "        business_review_dict[review[\"business_id\"]].append(review[\"review_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine keywords from all reviews, category, and name for each business\n",
    "# some businesses do not have any reviews, so we only combine category and name keywords for those businesses using dictionary\n",
    "business_keywords_combined = {}\n",
    "for business in businesses:\n",
    "    business_keywords_combined[business[\"business_id\"]] = []\n",
    "    if business[\"business_id\"] in business_review_dict.keys():\n",
    "        for review_id in business_review_dict[business[\"business_id\"]]:\n",
    "            business_keywords_combined[business[\"business_id\"]] += review_keywords[review_id]\n",
    "    business_keywords_combined[business[\"business_id\"]] += business_keywords[business[\"business_id\"]][\"category\"]\n",
    "    business_keywords_combined[business[\"business_id\"]] += business_keywords[business[\"business_id\"]][\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the keywords for each business with their name\n",
    "for business in businesses:\n",
    "    print(business[\"name\"] + \": \")\n",
    "    print(business_keywords_combined[business[\"business_id\"]])\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
