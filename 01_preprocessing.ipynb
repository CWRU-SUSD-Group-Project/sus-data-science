{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import statistics\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data/02_postprocessing direction if it does not exist\n",
    "if not os.path.exists(\"data/02_postprocessing\"):\n",
    "    os.makedirs(\"data/02_postprocessing\")\n",
    "# Create the data/02_postprocessing/sample directory if it does not exist\n",
    "if not os.path.exists(\"data/02_postprocessing/sample\"):\n",
    "    os.makedirs(\"data/02_postprocessing/sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silent_remove(filename):\n",
    "    try:\n",
    "        os.remove(filename)\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed so that it can be run on the sample data or the full data just by switching one variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to True to run the script on the sample data\n",
    "# Set this to False to run the script on the full data (takes much longer)\n",
    "SAMPLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section performs rating normalization (technically standardization) to all ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [!] 4 minutes to load\n",
    "with open(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}ratings.json\") as f:\n",
    "    ratings_original = [json.loads(line) for line in f]\n",
    "with open(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}users.json\") as f:\n",
    "    users_original = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings_dict = {}\n",
    "for rating in ratings_original:\n",
    "    user_id = rating[\"user_id\"]\n",
    "    if user_id not in user_ratings_dict.keys():\n",
    "        user_ratings_dict[user_id] = {\"rating_objs\": [rating], \"ratings\": [(rating[\"rating_id\"], rating[\"stars\"])]}\n",
    "    else:\n",
    "        user_ratings_dict[user_id][\"rating_objs\"].append(rating)\n",
    "        user_ratings_dict[user_id][\"ratings\"].append((rating[\"rating_id\"], rating[\"stars\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to determine the cut off for how many ratings a user should have before we\n",
    "# apply z-score normalization\n",
    "\n",
    "# This outputs the ratio between the number of ratings that would be standardized\n",
    "# and all ratings in the dataset\n",
    "\n",
    "cutoff = 5\n",
    "num_ratings = [len(user[\"ratings\"]) for user in user_ratings_dict.values()]\n",
    "rating_count = Counter(num_ratings)\n",
    "rating_counter_agg = [(tup[0], tup[1], tup[0] * tup[1]) for tup in rating_count.items()]\n",
    "ratio = sum([tup[2] for tup in rating_counter_agg if tup[0] >= cutoff]) / sum([tup[2] for tup in rating_counter_agg])\n",
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_not_standardized = []\n",
    "users_standardized = []\n",
    "for user_id, user_ratings in user_ratings_dict.items():\n",
    "    if (\n",
    "        len(user_ratings[\"ratings\"]) >= cutoff\n",
    "        and len(set(list(zip(*user_ratings[\"ratings\"]))[1])) >= 2\n",
    "    ):\n",
    "        users_standardized.append(user_id)\n",
    "        user_ratings[\"avg_rating\"] = statistics.mean(\n",
    "            list(zip(*user_ratings[\"ratings\"]))[1]\n",
    "        )\n",
    "        user_ratings[\"std_dev\"] = statistics.stdev(\n",
    "            list(zip(*user_ratings[\"ratings\"]))[1]\n",
    "        )\n",
    "        user_ratings[\"standardized_ratings\"] = [\n",
    "            (\n",
    "                rating[0],\n",
    "                (rating[1] - user_ratings[\"avg_rating\"]) / user_ratings[\"std_dev\"],\n",
    "            )\n",
    "            for rating in user_ratings[\"ratings\"]\n",
    "        ]\n",
    "    else:\n",
    "        users_not_standardized.append(user_id)\n",
    "\n",
    "# Gather all ratings standardized by user\n",
    "user_standardized_ratings = [\n",
    "    rating\n",
    "    for user_ratings in [\n",
    "        user_rating\n",
    "        for user_rating in user_ratings_dict.values()\n",
    "        if \"standardized_ratings\" in user_rating.keys()\n",
    "    ]\n",
    "    for rating in user_ratings[\"standardized_ratings\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize all other ratings with respect to each other\n",
    "all_ratings = [\n",
    "    rating\n",
    "    for user_ratings in [\n",
    "        user_ratings_dict[user_id] for user_id in users_not_standardized\n",
    "    ]\n",
    "    for rating in user_ratings[\"ratings\"]\n",
    "]\n",
    "mean = statistics.mean(list(zip(*all_ratings))[1])\n",
    "std_dev = statistics.stdev(list(zip(*all_ratings))[1])\n",
    "pool_standardized_ratings = [\n",
    "    (rating[0], (rating[1] - mean) / std_dev) for rating in all_ratings\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of users: {len(user_ratings_dict)}\")\n",
    "print(f\"Number of users with at least {cutoff} ratings: {len(users_standardized)}\")\n",
    "print(f\"Number of users with less than {cutoff} ratings: {len(users_not_standardized)}\")\n",
    "print(f\"Number of ratings that were user-standardized: {len(user_standardized_ratings)}\")\n",
    "print(f\"Number of ratings that were pool-standardized: {len(pool_standardized_ratings)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = {rating[\"rating_id\"]: rating for rating in ratings_original}\n",
    "for rating in user_standardized_ratings + pool_standardized_ratings:\n",
    "    ratings[rating[0]][\"standardized_rating\"] = rating[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/02_postprocessing/{'sample/' if SAMPLE else ''}ratings.json\", \"w\") as f:\n",
    "    f.write(\"\")\n",
    "with open(f\"data/02_postprocessing/{'sample/' if SAMPLE else ''}ratings.json\", \"a\") as f:\n",
    "    for rating in ratings.values():\n",
    "        f.write(json.dumps(rating) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Businesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories >> Type, Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}businesses.json\") as f:\n",
    "    businesses = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count most frequently category occurrences in businesses.json\n",
    "category_counts = {}\n",
    "for business in businesses:\n",
    "    categories_str = business.get(\"categories\", '')\n",
    "    if categories_str:\n",
    "        categories = categories_str.split(', ')\n",
    "        for category in categories:\n",
    "            category_counts[category] = category_counts.get(category, 0) + 1\n",
    "\n",
    "# Find the most frequent categories\n",
    "category_counts = sorted(category_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "category_counts[:5]\n",
    "\n",
    "# Create a list of the most frequent categories\n",
    "top_categories = [category[0] for category in category_counts[:5]]\n",
    "\n",
    "# print the top 5 most frequent categories\n",
    "top_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the businesses that have at least one of the top 5 categories using a dictionary and create a new attribute \"type\" for each business that states which of the top 5 categories it belongs to\n",
    "businesses_dict = {}\n",
    "for business in businesses:\n",
    "    categories_str = business.get(\"categories\", '')\n",
    "    if categories_str:\n",
    "        categories = categories_str.split(', ')\n",
    "        for category in categories:\n",
    "            if category in top_categories:\n",
    "                business[\"type\"] = category\n",
    "                businesses_dict[business[\"business_id\"]] = business\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silent_remove(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}businesses.json\")\n",
    "with open(f\"data/01_cleaned/{'sample' if SAMPLE else ''}/businesses.json\", \"a\") as f:\n",
    "    for business in businesses_dict.values():\n",
    "        f.write(json.dumps(business) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# read business JSON file\n",
    "with open(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}businesses.json\") as f:\n",
    "    businesses = [json.loads(line) for line in f]\n",
    "\n",
    "# Extract keywords from each business entry for category and name attributes using dictionary\n",
    "business_keywords = {}\n",
    "for business in businesses:\n",
    "    business_keywords[business[\"business_id\"]] = {}\n",
    "    business_keywords[business[\"business_id\"]][\"category\"] = []\n",
    "    business_keywords[business[\"business_id\"]][\"name\"] = []\n",
    "    for word in word_tokenize(business[\"categories\"]):\n",
    "        if word not in stop_words and word != \",\" and word != \"&\" and word != \"-\" and word != \"(\" and word != \")\" and word != \".\" and word != \"'\" and word != \"!\" and word != \"?\" and word != \":\" and word != \";\" and word != \"[\" and word != \"]\" and word != \"/\":\n",
    "            business_keywords[business[\"business_id\"]][\"category\"].append(word)\n",
    "    for word in word_tokenize(business[\"name\"]):\n",
    "        if word not in stop_words and word != \",\" and word != \"&\" and word != \"-\" and word != \"(\" and word != \")\" and word != \".\" and word != \"'\" and word != \"!\" and word != \"?\" and word != \":\" and word != \";\" and word != \"[\" and word != \"]\" and word != \"/\":\n",
    "            business_keywords[business[\"business_id\"]][\"name\"].append(word)\n",
    "\n",
    "# read review JSON file\n",
    "with open(f\"data/02_postprocessing/{'sample/' if SAMPLE else ''}reviews.json\") as f:\n",
    "    reviews = [json.loads(line) for line in f]\n",
    "\n",
    "# Extract keywords from each review entry for text attribute using dictionary\n",
    "review_keywords = {}\n",
    "for review in reviews:\n",
    "    review_keywords[review[\"review_id\"]] = []\n",
    "    for word in word_tokenize(review[\"text\"]):\n",
    "        if word not in stop_words and word != \",\" and word != \"&\" and word != \"-\" and word != \"(\" and word != \")\" and word != \".\" and word != \"'\" and word != \"!\" and word != \"?\" and word != \":\" and word != \";\" and word != \"[\" and word != \"]\" and word != \"/\":\n",
    "            review_keywords[review[\"review_id\"]].append(word)\n",
    "\n",
    "# Create a dictionary of business_id to a list of review_ids\n",
    "business_review_dict = {}\n",
    "for review in reviews:\n",
    "    if review[\"business_id\"] not in business_review_dict.keys():\n",
    "        business_review_dict[review[\"business_id\"]] = [review[\"review_id\"]]\n",
    "    else:\n",
    "        business_review_dict[review[\"business_id\"]].append(review[\"review_id\"])\n",
    "\n",
    "# combine keywords from all reviews, category, and name for each business\n",
    "# some businesses do not have any reviews, so we only combine category and name keywords for those businesses using dictionary\n",
    "business_keywords_combined = {}\n",
    "for business in businesses:\n",
    "    business_keywords_combined[business[\"business_id\"]] = []\n",
    "    if business[\"business_id\"] in business_review_dict.keys():\n",
    "        for review_id in business_review_dict[business[\"business_id\"]]:\n",
    "            business_keywords_combined[business[\"business_id\"]] += review_keywords[review_id]\n",
    "    business_keywords_combined[business[\"business_id\"]] += business_keywords[business[\"business_id\"]][\"category\"]\n",
    "    business_keywords_combined[business[\"business_id\"]] += business_keywords[business[\"business_id\"]][\"name\"]\n",
    "\n",
    "\n",
    "\n",
    "# print the keywords for each business with their name\n",
    "for business in businesses:\n",
    "    print(business[\"name\"] + \": \")\n",
    "    print(business_keywords_combined[business[\"business_id\"]])\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
