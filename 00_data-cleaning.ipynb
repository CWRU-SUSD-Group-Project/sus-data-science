{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook cleaned the data and writes the cleaned data to the data cleaning folder. The primary task of the cleaning step is to remove the attributes that are not used in the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the necessary libraries and create the folders to store the cleaned data. We also define helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the \"data/01_cleaned\" directory if it doesn't exist\n",
    "if not os.path.exists(\"data/01_cleaned\"):\n",
    "    os.makedirs(\"data/01_cleaned\")\n",
    "# Create the \"data/01_cleaned/sample\" directory if it doesn't exist\n",
    "if not os.path.exists(\"data/01_cleaned/sample\"):\n",
    "    os.makedirs(\"data/01_cleaned/sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silent_remove(filename):\n",
    "    try:\n",
    "        os.remove(filename)\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed so that it can be run on the sample data or the full data just by switching one variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to True to run the script on the sample data\n",
    "# Set this to False to run the script on the full data (takes much longer)\n",
    "SAMPLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Businesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we clean the business dataset. We load the data and keep the attributes defined in the `keys_to_keep` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new list object 'business' (loading in the JSON file)\n",
    "with open(f\"data/00_original/{'sample/' if SAMPLE else ''}yelp_academic_dataset_business.json\", \"r\") as f:\n",
    "    businesses = pd.DataFrame([json.loads(line) for line in f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned unused attributes from the business data\n",
    "\n",
    "attributes_to_keep = [\n",
    "    \"longitude\",\n",
    "    \"name\",\n",
    "    \"categories\",\n",
    "    \"review_count\",\n",
    "    \"stars\",\n",
    "    \"latitude\",\n",
    "    \"business_id\",\n",
    "]\n",
    "\n",
    "businesses = businesses[attributes_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f\"data/01_cleaned/{'sample/' if SAMPLE else ''}businesses.csv\"\n",
    "with open(file_name, \"w\") as f:\n",
    "    businesses.to_csv(f, index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviews/Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we clean the data for reviews and users in much the same way as the business data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load review data\n",
    "# [!] 5 min\n",
    "with open(f\"data/00_original/{'sample/' if SAMPLE else ''}yelp_academic_dataset_review.json\", \"r\") as f:\n",
    "    review_df = pd.DataFrame([json.loads(line) for line in f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns not in the attributes_to_keep list\n",
    "\n",
    "attributes_to_keep = [\n",
    "    \"business_id\",\n",
    "    \"date\",\n",
    "    \"review_id\",\n",
    "    \"stars\",\n",
    "    \"text\",\n",
    "    \"user_id\",\n",
    "]\n",
    "\n",
    "review_df = review_df[attributes_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text column\n",
    "# [!] 4 min\n",
    "\n",
    "# Remove newlines from the text column\n",
    "review_df[\"text\"] = review_df[\"text\"].str.replace(\"\\n\", \" \")\n",
    "# Remove quotes from the text column\n",
    "review_df[\"text\"] = review_df[\"text\"].str.replace('\"', \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the review data to a CSV\n",
    "# [!] 4 min\n",
    "file_name = f\"data/01_cleaned/{'sample/' if SAMPLE else ''}reviews.csv\"\n",
    "with open(file_name, \"w\") as f:\n",
    "    review_df[[\"business_id\", \"review_id\", \"user_id\", \"text\"]].to_csv(f, index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we remove the review data and write a new file without the reviews. This is to save time and space in the preprocessing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df = review_df[[\"business_id\", \"review_id\", \"user_id\", \"stars\"]]\n",
    "rating_df = rating_df.rename(columns={\"review_id\": \"rating_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the ratings data to a CSV\n",
    "# [!] 4 min\n",
    "file_name = f\"data/01_cleaned/{'sample/' if SAMPLE else ''}ratings.csv\"\n",
    "with open(f\"data/01_cleaned/{'sample/' if SAMPLE else ''}ratings.csv\", \"w\") as f:\n",
    "    rating_df.to_csv(f, index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/00_original/{'sample/' if SAMPLE else ''}yelp_academic_dataset_user.json\", \"r\") as f:\n",
    "    users = pd.read_json(f, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_to_keep = [\n",
    "    \"average_stars\",\n",
    "    \"friends\",\n",
    "    \"name\",\n",
    "    \"review_count\",\n",
    "    \"user_id\",\n",
    "]\n",
    "\n",
    "users = users[attributes_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following step extracts the `friends` column and makes it its own data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the friends column into a separate table\n",
    "users[\"friends\"] = users[\"friends\"].apply(lambda x: x.split(\", \"))\n",
    "users[\"friends\"] = users[\"friends\"].apply(lambda x: [] if x == [\"None\"] else x)\n",
    "friends = users[[\"user_id\", \"friends\"]].explode(\"friends\").rename(columns={\"friends\": \"friend_id\"})\n",
    "friends.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = f\"data/01_cleaned/{'sample/' if SAMPLE else ''}users.csv\"\n",
    "with open(file_name, \"w\") as f:\n",
    "    users.to_csv(f, index=False, header=True)\n",
    "file_name = f\"data/01_cleaned/{'sample/' if SAMPLE else ''}friends.csv\"\n",
    "with open(file_name, \"w\") as f:\n",
    "    friends.to_csv(f, index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
